[{"content":"","date":null,"permalink":"/tags/development/","section":"Tags","summary":"","title":"Development"},{"content":"","date":null,"permalink":"/tags/devops/","section":"Tags","summary":"","title":"DevOps"},{"content":"","date":null,"permalink":"/","section":"PhiloBlog","summary":"","title":"PhiloBlog"},{"content":"","date":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"/tags/standards/","section":"Tags","summary":"","title":"Standards"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":" oAuth pprovides more flows than just the authentication of a user, but also authentication of services against one Authentication Server or a federated net of Authentication Servers. What was the basic oAuth flow and what to know additionally? #The Authorication Code Flow is the most common flow for authenticating a human against an Authorization Server, often combined with Open ID Connect. This flow is described in my last Post: Understanding oAuth Authentication Code Flow.\nTerminology #Actors:\nResource Owner - The human that can authenticate Resource Server - The server that holds the resources, for basic authentication this might be only the user identifier Client - The service that wants to know who the user is Authorization Server - The server that authenticates the user and issues tokens Access Token - credentials used to access protected resources. Refresh Token - credentials used to obtain a new access token when the current access token becomes invalid. The flows are defined in the RFC 67491, while I found the best overview at curity.io 2 and Auth0 3.\nClient Credentials Flow - A Service wants to authenticate against another service without a user present #This flow is used when the Client wants to authenticate itself against another service without an involved Human. This does not authenticate the Client as a specific user, but as a service; therefore, the Client does not get access to any human resources.\nThe benefit of this flow is that the Client can authenticate itself (e.g. against other microservices) in an unified way, with the possibility to change permissions on the fly, while minimizing the number of calls using static credentials.\nThe client authenticates with the authorization server and requests an access token from the token endpoint with its client_id, client_secret, and scope.\nclient_id, client_secret: The credentials of the Client to authenticate itself against the Authorization\nThe authorization server authenticates the client, and if valid, issues an access token.\n┌ │ └ ┌ │ └ ─ C ─ ─ C ─ ─ l ─ ─ l ─ ─ i ┬ │ │ │ │ │ │ ┴ i ─ ─ e ─ ─ ( \u0026lt; ─ e ─ ─ n ─ ─ 2 ─ ─ n ─ ─ t ─ ─ ) ─ ─ t ─ ┐ │ ┘ ─ ─ ┐ │ ┘ ─ { ─ ─ a ─ ( ─ c ─ 1 ─ c ─ ) ─ e ─ ─ s ─ { ─ s ─ c ─ _ ─ l ─ t ─ i ─ o ─ e ─ k ─ n ─ e ─ t ─ n ─ _ ─ , ─ i ─ ─ d ─ e ─ , ─ x ─ ─ p ─ c ─ i ─ l ─ r ─ i ─ e ─ e ─ s ─ n ─ _ ─ t ─ i ─ _ ─ n ─ s ─ , ─ e ─ ─ c ─ s ─ r ─ c ─ e ─ o ─ t ─ p ─ , ─ e ─ ─ , ─ s ─ ─ c ─ t ─ ┌ │ └ o ─ o ─ ┌ │ └ ─ A ─ p ─ k ─ ─ A ─ ─ u ─ e ─ e ─ ─ u ─ ─ t ─ } ─ n ─ ─ t ─ ─ h ─ ─ _ ─ ─ h ─ ─ o ─ ─ t ─ ─ o ─ ─ r ─ ─ y ─ ─ r ─ ─ i ─ ─ p ─ ─ i ─ ─ z ─ ─ e ─ ─ z ─ ─ a ─ \u0026gt; } ─ ─ a ─ ─ t ┬ │ │ │ │ │ │ ┴ t ─ ─ i ─ ─ i ─ ─ o ─ ─ o ─ ─ n ─ ─ n ─ ─ S ─ ─ S ─ ─ e ─ ─ e ─ ─ r ─ ─ r ─ ─ v ─ ─ v ─ ─ e ─ ─ e ─ ─ r ─ ─ r ─ ┐ │ ┘ ┐ │ ┘ Why use the Client Credentials Flow? #From the first look, the Client Credentials Flow seems to use static credentials, and there are not many benefits over API keys. From the security perspective, the Client Credentials Flow requests the authentication token from a Authentication Server, which might revoke the token if the Client is compromised (without an additional deployment). The Client can also request a new token with the refresh token, which is not possible with API keys.\nFrom a human developer perspective, the Client Credentials Flow is a unified way to authenticate services in a microservice environment. Unified means, testers or developers who join the team don\u0026rsquo;t need to be introduced to the authentication of the service whenever they switch teams, but can use the same flow for all services. DevOps Engineers can rely on the same flow for all services, which makes the deployment and monitoring easier.\nSuch human benefits are often underestimated, but neglecting them causes a lot of friction in the development process, deployment delays, and security issues.\nRefresh - A Service has a token and wants a new token without the user present #To keep the access token short-lived and the user experience smooth, the Client can request a new access token with the refresh token. To prevent malicious usage, the refresh_token in the response is not the same as the one that was sent and the Client has to update their refresh token.\n┌ │ └ ┌ │ └ ─ C ─ ─ C ─ ─ l ─ ─ l ─ ─ i ┬ │ │ │ │ │ │ ┴ i ─ ─ e ─ ─ ( \u0026lt; ─ e ─ ─ n ─ ─ 2 ─ ─ n ─ ─ t ─ ─ ) ─ ─ t ─ ┐ │ ┘ ─ ─ ┐ │ ┘ ─ { ─ ─ a ─ ( ─ c ─ 1 ─ c ─ ) ─ e ─ ─ s ─ { ─ s ─ c ─ _ ─ l ─ t ─ i ─ o ─ e ─ k ─ n ─ e ─ t ─ n ─ _ ─ , ─ i ─ ─ d ─ r ─ , ─ e ─ ─ f ─ c ─ r ─ l ─ e ─ i ─ s ─ e ─ h ─ n ─ _ ─ t ─ t ─ _ ─ o ─ s ─ k ─ e ─ e ─ c ─ n ─ r ─ , ─ e ─ ─ t ─ e ─ , ─ x ─ ─ p ─ r ─ i ─ e ─ r ─ f ─ e ─ r ─ s ─ e ─ _ ─ s ─ i ─ h ─ n ─ _ ─ , ─ t ─ ─ o ─ s ─ k ─ c ─ e ─ o ─ n ─ p ─ , ─ e ─ ─ , ─ s ─ ─ c ─ t ─ ┌ │ └ o ─ o ─ ┌ │ └ ─ A ─ p ─ k ─ ─ A ─ ─ u ─ e ─ e ─ ─ u ─ ─ t ─ } ─ n ─ ─ t ─ ─ h ─ ─ _ ─ ─ h ─ ─ o ─ ─ t ─ ─ o ─ ─ r ─ ─ y ─ ─ r ─ ─ i ─ ─ p ─ ─ i ─ ─ z ─ ─ e ─ ─ z ─ ─ a ─ \u0026gt; } ─ ─ a ─ ─ t ┬ │ │ │ │ │ │ ┴ t ─ ─ i ─ ─ i ─ ─ o ─ ─ o ─ ─ n ─ ─ n ─ ─ S ─ ─ S ─ ─ e ─ ─ e ─ ─ r ─ ─ r ─ ─ v ─ ─ v ─ ─ e ─ ─ e ─ ─ r ─ ─ r ─ ┐ │ ┘ ┐ │ ┘ Token Exchange Flow - A Service has a token, but wants one from a different Authentication Authority #If a Client has an access token from one Authorization Server, it may need a token from the same Authorization Server with other privileges to conform the least-privileges principle. Token exchange also allows you to cross security domains by exchanging a token from one trust domain to a token of a different one.\nSubject token - The token that the Client has Actor token - Optional Deligation token if the Client acts on behalf of a human or another service Requested token - The token that the Authorization Server returns In processing the request, the authorization server must perform the appropriate validation procedures for the indicated token type and, if the actor token is present, also perform the appropriate validation procedures for its indicated token type.\n┌ │ └ ┌ │ └ ─ C ─ ─ C ─ ─ l ─ ─ l ─ ─ i ┬ │ │ │ │ │ │ ┴ i ─ ─ e ─ ( ─ \u0026lt; ─ e ─ ─ n ─ 1 ─ ─ ─ n ─ ─ t ─ ) ─ ─ ─ t ─ ┐ │ ┘ ─ ( ─ ┐ │ ┘ { ─ 2 ─ a ─ ) ─ c ─ ─ t ─ { ─ o ─ a ─ r ─ c ─ _ ─ c ─ t ─ e ─ o ─ s ─ k ─ s ─ e ─ _ ─ n ─ t ─ , ─ o ─ ─ k ─ a ─ e ─ c ─ n ─ t ─ , ─ o ─ ─ r ─ i ─ _ ─ s ─ t ─ s ─ o ─ u ─ k ─ e ─ e ─ d ─ n ─ _ ─ _ ─ t ─ t ─ o ─ y ─ k ─ p ─ e ─ e ─ n ─ , ─ _ ─ ─ t ─ s ─ y ─ u ─ p ─ b ─ e ─ j ─ , ─ e ─ ─ c ─ t ─ t ─ o ─ _ ─ k ─ t ─ e ─ o ─ n ─ k ─ _ ─ e ─ t ─ n ─ y ─ , ─ p ─ ─ e ─ s ─ , ─ u ─ ─ b ─ e ─ j ─ x ─ e ─ p ─ c ─ i ─ t ─ r ─ _ ─ e ─ t ─ s ─ o ─ _ ─ k ─ i ─ e ─ n ─ n ─ , ─ _ ─ ─ ┌ │ └ t ─ s ─ ┌ │ └ ─ A ─ y ─ c ─ ─ A ─ ─ u ─ p ─ o ─ ─ u ─ ─ t ─ e ─ p ─ ─ t ─ ─ h ─ , ─ e ─ ─ h ─ ─ o ─ ─ } ─ ─ o ─ ─ r ─ ─ ─ ─ r ─ ─ i ─ ─ ─ ─ i ─ ─ z ─ . ─ ─ ─ z ─ ─ a ─ } \u0026gt; ─ ─ a ─ ─ t ┬ │ │ │ │ │ │ ┴ t ─ ─ i ─ ─ i ─ ─ o ─ ─ o ─ ─ n ─ ─ n ─ ─ S ─ ─ S ─ ─ e ─ ─ e ─ ─ r ─ ─ r ─ ─ v ─ ─ v ─ ─ e ─ ─ e ─ ─ r ─ ─ r ─ ┐ │ ┘ ┐ │ ┘ { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The Request of the Client to exchange the code for an access token.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;grant_type\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The value must be `urn:ietf:params:oauth:token-type:access_token` to indicate that a token exchange is being performed\u0026#34; }, \u0026#34;resource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;A URI that indicates the target service or resource where the client intends to use the requested security token\u0026#34; }, \u0026#34;audience\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The logical name of the target service where the client intends to use the requested security token\u0026#34; }, \u0026#34;scope\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Additional (space separated) resources of the requested token\u0026#34; }, \u0026#34;requested_token_type\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;An identifier for the type of the requested security token\u0026#34; }, \u0026#34;subject_token\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;A security token that represents the identity of the party on behalf of whom the request is being made\u0026#34; }, \u0026#34;subject_token_type\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;An identifier for the type of the subject token\u0026#34; }, \u0026#34;actor_token\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;A security token that represents the identity of the acting party\u0026#34; }, \u0026#34;actor_token_type\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;An identifier for the type of the actor token. Required when the actor_token parameter is present\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;grant_type\u0026#34;, \u0026#34;subject_token\u0026#34;, \u0026#34;subject_token_type\u0026#34; ] } The Token Types are defined in the RFC, for example urn:ietf:params:oauth:token-type:access_token Indicates that the token is an OAuth access token issued by the given authorization server.\nWhy use the Token Exchange Flow? #A big request for the Token Exchange Flow is to enable a federated network of Authentication Authorities. Here are some use cases4:\nPipelines with tokens instead of credentials\nCI/CD pipelines that need to authenticate against a different service to upload artifacts or read secrets. Github (but also Gitlab) injects a token into the pipeline 5, which can be used to access some github endpoints, but also to be exchanged for a token from another Authentication Authority, like your artifact repository 6, or accessing some other resources. For this to work, the Authentication Authority must trust the token from Github, and still validate the token (not every Github token is should access the resources).\nUsing federated authentication to authenticate against third parties\nWhen working with third parties authentication is often a pain, eased by static credentials. But with the Token Exchange Flow, the Client can authenticate against the third party with a token from the Authorization Server (if both parties are willing to use oAuth). Again the Authorization Server must trust the third party Authorisation Server and validate the token.\nOne benefit of this is again that the token may be revoked. If a service is deployed already with token (like some cloud provider already inject into the container), the token can be exchanged at the third party Authentication Server for a third party resource authorizing token. After a new deployment, the previous token can be revoked, meaning in case of a breach a redeployment is enough to revoke the access.\nAgain, this requires trust between the Authentication Authorities.\nUp or downstreaming tokens\nSometimes, the current token is not enough to access a resource, but the Client can exchange the token for a new one with higher privileges - or vice versa (to not use a token with too many privileges, following the least-privileges principle).\nConnect a service with oAuth that otherwise does not comply\nImagine working on a project, that does not support oAuth, while all other surrounding (and depending) services do. Exchanging an injected token for a token that the service can use to authenticate against other services might be a first step into a more secure and easier to use environment.\nOther flows #There are more flows in the oAuth specification, which are not covered in this post, but honorable mentions are:\nDevice Flow: A Service wants to authenticate a User on a device with limited input capabilities (e.g. a TV)\nRevoke Flow: A Service wants to invalidate a refresh token before it expires\nConclusion #oAuth can do so much more than just authenticate a human against an Authorization Server.\nI made the experience, that developer do underestimate the benefits of using oAuth for services, and overestimate the complexity (if libraries are used). Not only user facing, but also in the pure service-to-service communication, oAuth provides a unified way to authenticate services over different domains.\nHappy Coding :)\nRFC 6749 - The OAuth 2.0 Authorization Framework\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe OAuth 2.0 by Curity\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe OAuth 2.0 by Auth0\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMore on token exchanges\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGitHub Tokens\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFederated CI/CD Pipelines Authentication without Secrets\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"10 September 2024","permalink":"/posts/2024-09-o-auth-2/","section":"Posts","summary":"oAuth pprovides more flows than just the authentication of a user, but also authentication of services against one Authentication Server or a federated net of Authentication Servers.","title":"Understanding other oAuth flows"},{"content":" oAuth is a hard to get into because of its (necessary) complexity. A basic understanding of the standard flow and the actors involved can help to make better decisions and understand the security implications of the choices. Who is the User and how trivial is this question? #A Service need to know who the requesting user is, what the user is allowed to do and if that information is still valid. The most common way to achieve this is by using static credentials (like username and password) - assuming that if the credentials are known, the requesting user must be the user to which the credentials belong. Such static credentials often come with a lot of problems 1:\nAnyone with the credentials can impersonate the user Static credentials may be brute-forced or leaked Humans are humans and will write them down, use them multiple times, or share them with others It\u0026rsquo;s hard to revoke credentials without changing them or the system Credentials don\u0026rsquo;t include any information about the user or their permissions Credentials are often used for a long time because changing them is hard (and humans don\u0026rsquo;t like it) Instead of trusting that only the two parties know the static credentials, a service should trust a third party to verify the identity of the user. One very simple implementation including a third party is using the mail provider as authentication authority. The user logs in with the email and a random string that was sent to the email.\nHowever, this flow is neither very secure nor very user-friendly. The user has to switch between their email client and the application; and mails offer many attack vectors, with the simplest being that the mail is intercepted used for authentication before the user can use it.\nWhy oAuth and why is it so complicated? #If you log in to a service by authenticating against a different service, you might use oAuth. The process of clicking on \u0026ldquo;login using xyz\u0026rdquo; on a website that is not xyz, entering your credentials for xyz, and then being redirected back is the oAuth flow.\n\u0026ldquo;But what about OpenID Connect?\u0026rdquo; OpenID Connect is a layer on top of oAuth that adds an identity layer. In theory, oAuth can work by only providing an access token with a scope (which can be used as permissions) without any information about the user. OpenID Connect builds on the oAuth protocol and adds an identity layer. 2\nAuthentication is a requirement that so many services have in common, and therefore a range of attacks on user identity have been developed. The need for an user-friendly authentication that also considers even unknown attack vectors is why oAuth was defined - it is a protocol that that defines how a service may authenticate a user in diverse use cases. It contains flows that might appear complicated at first, but are necessary to cover all attack vectors and use cases.\nTerminology #Actors:\nResource Owner - The human that can authenticate Resource Server - The server that holds the resources, for basic authentication this might be only the user identifier Client - The service that wants to know who the user is Authorization Server - The server that authenticates the user and issues tokens As precondition, the Client must register themselves at the Authorization Server to get their own client_id to identify themselves towards this Authorization Server.\nEach request should contain the grant_type to specify the flow that is used.\nTokens:\nAccess Token - credentials used to access protected resources. The access token provides an abstraction layer, replacing different authorization constructs (e.g., username and password) with a single token understood by the resource server. Refresh Token - credentials used to obtain a new access token when the current access token becomes invalid or expires. The Access Token should be short-lived to minimize the damage if it ever got stolen or invalid. If the human decides to revoke the access, the Access token may remain valid, but the Refresh token will not work anymore. Json Web Tokens (JWT) are a common format for tokens. The RFC which defines oAuth does not specify the token format, but JWT is very common, because it can be easily signed/validated and can contain all necessary information.\nOpenID Connect uses JWT as the token format, but oAuth does not require JWT.\noAuth Authentication Flows # It is okay to not understand every protocol detail - a web developer doesn\u0026rsquo;t need to know all about oAuth flows to authenticate a user if they just use an existing library and authentication service. For most languages and frameworks, there are libraries that implement oAuth and make it easy to use. The flows are defined in the RFC 67493, while I found the best overview at curity.io 4 and Auth0 5. Swagger provides some open api specifications for oAuth flows 6.\nBrowser Flow - A Service wants to know who the user is # The Client initiates the flow by directing the human to the Authorization Server. The Client includes its client_id, scope, state, code_challenge and redirect_uri. { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The Request with which the client starts the oAuth flow to receive a token.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;client_id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The ID of the requesting client obtained when registering the client with the Authorization Server.\u0026#34; }, \u0026#34;response_type\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Defines the flow type, this post only covers the latest `code` flow.\u0026#34; }, \u0026#34;scope\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Additional (space separated) resources of the human. The Client may request certain scopes (e.g. access to the users photos), the Authorization Server may ignore them based on their policy or the humans instructions (e.g. the human may have disabled the sharing of their photos during the consent step)\u0026#34; }, \u0026#34;state\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Client generated string to maintain state between the request and callback (like a authentication-attempt-id for the Client) to prevent cross-site request forgery\u0026#34; }, \u0026#34;redirect_uri\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The URI to which the human will be redirected after the Authorization Server has processed the request and the human has granted access.\u0026#34; }, \u0026#34;code_challenge\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;A hash of a random string (the `code_verifier`) that the Client will use to authenticate itself later\u0026#34;, } }, \u0026#34;required\u0026#34;: [ \u0026#34;client_id\u0026#34;, \u0026#34;response_type\u0026#34; ] } The Authentication Server checks if the redirect_uri is registered for the client_id to prevent Redirect URI manipulation (that would authenticate the human for one Client and then redirect the human and access information to an evil side). Then the Authentication Server authenticates the resource owner and requests grating.\nThe Authorization Server redirects the Human back to the Client to the redirect_uri. The redirection URI includes an authorization code and the state provided by the Client earlier.\n{ \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The \u0026#39;response\u0026#39; (but a http request to the `redirect_uri` from the Authorization Server to the Client after the human has granted access\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;state\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The state that was provided by the Client to identify the started flow attempt.\u0026#34; }, \u0026#34;code\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;A code with which the Client can request an access token from the Authorization Server. The Authorization Server does not directly add the access code to the redirected uri to make sure that the access token is not visible in the Humans side history and could then be misused\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;state\u0026#34;, \u0026#34;code\u0026#34; ] } The Client check if the given state matches the stored state (so this oAuth attempt is the same that was started on this earlier).\nThe Client requests an access token from the Authorization Server by providing the code, redirect_uri, and the original `code to authenticate itself.\n{ \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The Request of the Client to exchange the code for an access token.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;client_id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The ID of the requesting client obtained when registering the client with the Authorization Server.\u0026#34; }, \u0026#34;grant_type\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;value must be set to `authorization_code`\u0026#34; }, \u0026#34;code\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The authorization code received from the Authorization server\u0026#34; }, \u0026#34;redirect_uri\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The same redirect_uri that was used in the first request\u0026#34; }, \u0026#34;code_verifier\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The original code_verifier that was used to hash the code_challenge\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;client_id\u0026#34;, \u0026#34;grant_type\u0026#34;, \u0026#34;code\u0026#34;, \u0026#34;redirect_uri\u0026#34; ] } The Authorization Server validates the authorization code, hashes the given code_verifier to check if it matches the previous code_challange to ensure that the service who requests the access token is actually the service that started the process, and ensures that the redirect_uri matches the URI used to redirect the Client in step 3 to ensure that the intended uri is still the same. Finally, the Authorization Server responds back with an access token and, optionally, a refresh token. H u m a n C C l o i n c s k e n o t n \" L o g i n u s i n g G i t h u b \" \\ C l i e n t ( ( 1 5 ( ( ) ( ) 1 1 4 ) ) { ) { c c S S l C l t t i h i o o e e e r r n c n e e t k t _ _ \" \" i i i ( s c d f d 6 t o , , ) ( a d \" 6 t e r s c C ) e _ e t o h \" v s a d e { e p t e c a t r o e , k c o f n \" c i s c i e i e e t o f s d r _ ( h d ( ( s e \" t 3 e e 6 h 6 _ n y ) _ ) a ) t t t p s v s o i o e R a e C h C k f , e m r h e h e y l ( d e i e d e n a s 2 i f c c , t t t ) r a i k c k h e a e s e o r e r t C c r i d i e e h t i , f e f f s p , e n _ r t r c r a v a e a o c k t t e u e u s r o o o h d t r t h t f d i e i h f h _ e e f r r o i o t d i _ e b e r e r o d c r d e c i r i k f e h e i g t s s e l n a d r i _ a m a n o t l i e n u t a t , w i l r c n r i t i t e e t i i o c o e y n c _ n } n h n x g t u g _ e _ p e _ r c s c i , u i o o r r S , d p d e r i h e r e s e o w e _ d b w i b v b i i e t e e e n r l l h l o l , e o o o u o c n g a n s n s t g i u g g c _ s n t s c s o u / h o p r t c o t d t e i o o r o e o , } n i _ c s s c c c t l e a l h l o i n t i a i k A e t i e l e e u n o n l n n t t s n t a t _ h _ c _ _ n _ t o i r c i g i y r d e o d e d p i e d e z n e } a t i o n S e r v e r Conclusion #oAuth web flow is a complex protocol that is necessary to cover all attack vectors and use cases, but enables a secure and convenient way of authentication and authorisation. The complexity of the protocol is hidden behind libraries, but a developer who is aware of the flows can make better decisions and understand the security implications of their choices.\nBecause the complexity is hidden, developers should not hesitate to use oAuth for their services. It is a secure, user-friendly way to authenticate users and should be preferred over static credentials.\nHappy Coding :)\nStatic Credentials and why they are one of the biggest hazards in modern IT\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOpenID Connect\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRFC 6749 - The OAuth 2.0 Authorization Framework\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe OAuth 2.0 by Curity\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe OAuth 2.0 by Auth0\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSwagger oAuth Flows\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"9 September 2024","permalink":"/posts/2024-08-o-auth/","section":"Posts","summary":"oAuth is a hard to get into because of its (necessary) complexity.","title":"Understanding oAuth Authentication Code Flow"},{"content":"","date":null,"permalink":"/tags/agile/","section":"Tags","summary":"","title":"Agile"},{"content":" Architecture is no longer a set of diagrams that define upfront how features are implemented, but a continuously growing and evolving set of decisions Agile Architecture #One change that came with the agile culture was replacing detailed architecture plans and class structure diagrams \u0026ldquo;YAGNI\u0026rdquo; mentality of only developing the current ticket losing overview over the bigger picture. Both extremes are not practical and will end up in an agile architecture.\nThe term Agile Architecture implies that a software system is designed in a versatile, easy to-evolve, changeable way, while also being resilient to change; but also that the architecture is contiguously growing in an iterative live cycle to evolve with respect to the upcoming features of the product.1\nIn every software project, some decisions need to be made upfront, that will highly influence the architecture of the project - programming language, database decision, authentication, patterns \u0026hellip; These decisions should not be solved by the first feature ticket by one developer. But I had the experience that exactly that happens - one developer gets the task of \u0026ldquo;build the project\u0026rdquo;, locks themselves in a dark room and emerges after weeks with a barebone of a project every other team member is forced to use from that point on.\nDefining Architecture and their Requirements #From my idealistic point of view, the architecture decisions should be discussed in the team, after understanding the idea of the product, to design an agile architecture that is flexible enough to be iterated on. For this to work, architecture can not be defined the same way as in Waterfall projects in which the architecture was designed and set in stone before the first ticket was started. \u0026ldquo;The software architecture isn\u0026rsquo;t a set of diagrams, it\u0026rsquo;s not a set of review meetings, it\u0026rsquo;s not a software architecture document, but it is a set of decisions that the team makes about some critical aspects of the system\u0026rdquo;. 2\nCapturing and Documenting Architecture #Viewing Architecture as a set of decisions makes the Architecture Decision Records a very relatable way of documenting architecture. Drawing fancy diagrams - something I enjoy to do - is a great way to document how a system is working, but often enough the question of why it was built this way is the more important question if developers see themselves confronted with the need for change.\nArchitecture Design Records: A set of point in time documentation of architectural decisions, usually stored in the code base to get information on the thoughts and reasons why the code was implemented in a certain way. I wrote more about it in this post. The boundary of the architectural decision in contrast to an implementation decision is not easy, by may be defined for practical reasons - if the cost of changing a decision, it is probably an architectural decision.\nArchitecture Perspectives for Requirements #While Agile Methodoolgies provide a wide range of tools to define the requirements for products from a user and a business perspective; they often lack the perspective of an architect, future developer, or tester. When formulating the User Story, the architectural requirements are often left out, which means in agile they are invisible to time constraints, deadlines, and work recognition.\nThere is one common framework existing that deals with the definition of such architectural or quality attribute requirements: The Six Part Scenario\nSource of stimulus (some entity or event, e.g. an user, an attacker) Stimulus (condition that needs to be considered, e.g. faulty request) Environment (providing context, e.g. during overloaded times, while DB is recovering from an error) Artifact (what part of the system is acting) Response (activity undertaken after the arrival of the stimulus, e.g. reporting, escalating, restarting) Response measure (make the response measurable and testable) 3 Some examples of these requirements, that highly interfere with the the architecture:\nA User requires the handling of a large numbers items by a micro service, in an environment that does not require sync processes, but handling of the micro service failing; the services uses an async communication, the current state and number of tries should be reported (may lead to a Queue that supports retry mechanisms) An event is dispatched to trigger a command, but the command will fail as the Database is currently recovering; the command should be retried automatically several times before it failes and reports an error. One User requests a separate file format and therefore requires the usage of a different (third party) service instead of the most used, in a normal busines environment; the system should be able to automatically detect file format by input and switch the service used, the used client should be stored and visible to the user. (Might lead to something like a driver pattern) A User want to authenticate against the system and related micro services in a normal busines environment; The authentication process should include the permissions to also authenticate against the microservices, the system should run without a separate authentication (might lead to something like oAuth) A User requests a list of data enteries without the need to store something, during a timeslot with very high demand; the system should direct such request to a read replica of the DB; the Master-DB statistics should reflect a much lower number of only read statements (might lead to Query Command Segragation) These requirements match partially with the idea of non-functional requirements; but functional requirements do not by definition have the major impact on development cost. Architectural / Design Requirements may enable or stop non functional requirements, and functional requirements should be consulted to create architectural decisions. How many microseconds a request may take is a non-functional requirement that may be satisfied without making costly future decisions. As sidenote, the idea of framing non-functional requirements in a quantitative, measurable, testable number (target number and unacceptable number) also underlines that these requirements are revisited regularly, influenced by the architecture, but not causing architectural changes per se 4.\nHow to design Agile Architecture #Minimal Viable Architecture #Similar to the concept of a Minimum Viable Product, the idea of a Minimum Viable Architecture is to deliver an architecture that fulfils the current point in time relevant requirements. This architecture is iterated over in the upcoming features and requirements.5\nModel the architecture: The Model should be a tool for communication (not documentation) Consider Alternatives: Following the LEAN principles, discuss more than one option and consider drawbacks and benefits Mind Conways Law: Companies tend to implement systems that reflect their communication structure. If there is no functioning communication structure to the team that builds the service that your system requires, the implementation might reflect that Architect for change: The Architecture will change within the agile process, it can not and should not be defined in a way that eliminates future opportunities Mind testability, deployability, and developer usability: The Devs, Testers, and Infras are the users of the architecture that is built. It should be clear and easy to use it. Keep minimal viable: Travel light - Making too many decisions too early might restrict future implementations. If there is a decision that might as well be set in stone later, delay it Feedback loops #One of the from my point of view most important perspectives of the Quality Attribute Requirements is the visibility of the result. How are those architectural requirements visible to the user, the dev (so the user of the code), or the tester?\nLooking at the former requirements, the respective user may be asked if the decisions led to the desired quality attributes. When a new Developer joins the team, is the code structure easy to follow and understand? How clear is it for the tester to confirm the testability? How easy is the project to deploy and how often do the architecture decisions cause interruptions? Do the current devs enjoy working in the architecture?\nRefining such quality attributes and assessing them across teams might be a part of the modern interpretation of an architect\u0026rsquo;s role.\nConclusion #Architecture is no longer a step in development, but a continuous process of iterative decisions. As those decisions happen in strong coupling with the current product requirements and the developers who are working on the code they can and should not be practised in a closed room, but in an open space. Architecture decisions should be documented, evaluated, experimented, and assessed.\nHappy Coding :)\nHow to Agilely Architect an Agile Architecture\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nContinuous Architecture with Kurt Bittner and Pierre Pureur\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSoftware Architecture in Practice, Felix Bachman and Mark Klein\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nNon Functional Requirements\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMinimal Viable Architecture\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"28 May 2024","permalink":"/posts/2024-05-agile-architecture/","section":"Posts","summary":"Architecture is no longer a set of diagrams that define upfront how features are implemented, but a continuously growing and evolving set of decisions Agile Architecture #One change that came with the agile culture was replacing detailed architecture plans and class structure diagrams \u0026ldquo;YAGNI\u0026rdquo; mentality of only developing the current ticket losing overview over the bigger picture.","title":"Agile Software Architecture"},{"content":" Event Sourcing is a software pattern for stateful entity management. Instead of storing the current state of an Entity, only the state changes are stored. This blog post is about the advantages and disadvantages of the pattern, and how to avoid some challenges I faced in long living projects. About Event Sourcing #Event Sourcing is a software pattern for stateful entity management. Instead of storing the current state of an ( aggregate) entity, the state is derived from a sequence of (domain) events.\nTo implement such a pattern, the entity must have some kind of livecycle. This can be a finite state machine, for example the state of an order (placed, paid, shipped, delivered, returnRequested \u0026hellip;); or a tracking of state like a bank account (+12.4€, -0.33€, +145.29, \u0026hellip;). In any case, the final entity state is derived from the sequence of events that happened to the entity.\nImplementation Idea #Arbitrary Idea for the Implementation: \u0026ldquo;As a Dog Owner, I want a system to track the contest results of my dog\u0026rdquo;.\nLet\u0026rsquo;s start with the event requirements. The Product/Dog Owner wants a list of all the contests, and track the current state of their dog. This includes if the current local Dog License is passed or not, what the last achievement was, and what the all-time record ranking of the dog is.\nabstract class Achievement { public readonly DateTime $recordedAt = new DateTime(); public function __construct(private string $contestIdentifier, DateTimeImmutable $recordedAt = null) { $this-\u0026gt;recordedAt = $recordedAt ?? new DateTime(); } } class ObedienceAchievement extends Achievement { public function __construct(private string $contestIdentifier, private int $points, private int $ranking, DateTimeImmutable $recordedAt = null) { parent::__construct($this-\u0026gt;contestIdentifier, $recordedAt); } } class DogLicenseAchievement extends Achievement { public function __construct(private string $contestIdentifier, private bool $passed, DateTimeImmutable $recordedAt = null) { parent::__construct($this-\u0026gt;contestIdentifier, $recordedAt); } } // The Event Table CREATE TABLE achievements ( id UUID NOT NULL, dog_id UUID NOT NULL, context_identifier VARCHAR NOT NULL, recorded_at TIMESTAMP NOT NULL, data JSON NOT NULL, ); This makes storing new achievements very easy, the controller can do a single, very fast query to add the newest achievement to the database without caring about any state change. Because of the different event types with different data, the data column is a JSON column, like no developer ever regretted adding json data fields in relational databases. The dogId is not part of the event, but part of the table to ensure a foreign relation to a dogs table, which holds data that does not change the state, e.g. the breed, owner, or birthday.\nNow to the entity, the Dog. Ignoring the contents of the dogs table, the Dog Entity is made up of an apply function, which on instantiation applies each event until the current state is reproduced.\nclass Dog { private array $achievements = []; private bool $dogLicensePassed = false; private ?int $allTimeRanking = null; private ?int $lastObediencePoints = null; private ?DateTime $lastAchievement = null; public function apply(array $achievements): void { $this-\u0026gt;achievements[] = $achievement; foreach ($achievements as $achievement) { $this-\u0026gt;lastAchievement = $achievement-\u0026gt;recordedAt; switch (true) { case $achievement instanceof ObedienceAchievement: $this-\u0026gt;lastObediencePoints = $achievement-\u0026gt;points; $this-\u0026gt;allTimeRanking = $this-\u0026gt;allTimeRanking === null ? $achievement-\u0026gt;ranking : min($this-\u0026gt;allTimeRanking, $achievement-\u0026gt;ranking); break; case $achievement instanceof DogLicenseAchievement: $this-\u0026gt;dogLicensePassed = $achievement-\u0026gt;passed; break; } } } } The apply function is called with the events from the database, and the entity is in the correct state. For this pattern a repository is pattern that will help to control the hydration from the DB. 1\nAdvantages #Especially when coming from Eloquents Active Record Pattern, this seems a bit complicated, and require some awareness of the benefits of segregating storing state changes and querying the state.\nAudit Trail: The event table is a perfect audit trail, as it holds all the changes to the entity. For some projects of the financial sector this can be required by law, for others a history is \u0026ldquo;only\u0026rdquo; a required user feature, and worst case this is great to replay the state of the entity at any given point in time for debugging. 2 Scalability: The event table is append only, which makes it very easy to scale the database. The only thing that needs to be ensured is that the events are stored in the correct order. Also horizontal scaling can become very easy as splitting by dog_id can be done. Performance: The event table is very fast to write, and the separation of query and command ensures that the database is not blocked by long running queries. For many use cases the reliability of storing has a higher priority. Simplicity: Since years devs (in my bubble) are discussing event sourcing as great pattern, so many devs are aware of the pattern and will know their way around the code. Testing: Any testcase can be defined and prepared by the starting list of events, and the expected state of the entity. This makes testing very easy, and the tests very readable. Disadvantages # Memory: Besides the really big table that holds the event data, in our case with the potentially big JSON column, the entity in memory can become quite big. When one entity is loaded, all events need to be applied to the entity, and therefore fetched into RAM. Those are problems that are manageable, but need to be considered. Eventual consistency: The entity is not in a consistent state at any given point in time. There might be two events simultaneously that change the same state, and the order of the events is important. Again here are technical solutions like locking, or business solutions like making each event idempotent. Querying: The json column might hold events of different types, and the query to get the current state of the entity can become quite complex. This can be solved by a view, or by storing important information as separate columns (like in this case contestIdentifier). But when the Product/Dog Owner wants to know if one dog is the best of breed in all Obedience Contests, the query can become quite complex, when also all other achievements have to be sorted out. Serialization: The JSON column might hold old events, former versions. The serialization of the events might change, and the entity might not be able to apply the old events. This can be solved by versioning the events and a custom deserialization. Event Sourcing in long living projects #In theory many software patterns are great, but implementing them in a long living project can reveal some challenges. I would like to share some solutions of the challenges I faced.\nThe database decision #If the goal of the event sourcing is only storing the current value over time - hold your horses dear PHP Devs - maybe a relational database is not what you are looking for. Time series databases might be an option. On the other hand if you don\u0026rsquo;t need to query too much, and just hold the maybe changing data points, a document oriented database might the easiest solution.\nIf you go the for the relational database, most probably because you have a somewhat structured data model and the requirement to query large sets of data points based on properties in typed columns, there still might be a need for a json column. If I could choose to avoid it, I would. If the feature sets does not allow avoiding it, I highly recomend Postgres\u0026rsquo; jsonb column (with or without an index) over mariaDbs json column. 3\nEvent Versioning using a discriminator map #The day might come in which the event structure changes. A new field is added to an event, an old event is obsolete - one day there will be an event stored in the database that is not easily applied to the entity. An implementation where this can not happen, because all events are serialized to the same class, with the identifier stored in an enum to hide the complexity of versioning is possible - which would make this paragraph obsolete. Often the different events are instantiated to different classes.\nDecisions like how to name the identifier and what process to follow when an event is changed should be discussed in the team and best case documented in e.g. Architecture Decision Records. There needs to be an identifier to the type. In the easiest implementation the fully classified class name is stored in the database - which would cause migrations on a directory name change. Therefore, the identifier should be a string. As the string should be only used by the constant, it doesn\u0026rsquo;t need to be human-readable.\n// a string identifier with version public const ACHIEVED_OBEDIENCE = \u0026#39;achieved.v1.obidience\u0026#39;; // a string that is non human-readable, to decouple class name and identifier public const ACHIEVED_OBEDIENCE_V2 = \u0026#39;achieved.cda6d2f8-feaf-4818-a061-95228e0f3957\u0026#39;; In Laravel this can be handled by Morph Maps and a Morph Many Relationship 4.\nRelation::enforceMorphMap([ Achievement::ACHIEVED_OBEDIENCE_V1, Achievement::ACHIEVED_OBEDIENCE_V2 =\u0026gt; ObedienceAchievement::class, Achievement::ACHIEVED_DOG_LICENSE_V1 =\u0026gt; DogLicenseAchievement::class, ]); In Symfony the instantiation often happens more declarative, which also might cause a lot more boilerplate code. But Symfony does support a similar feature 5. These exact implementation will not be discussed here, as I personally had multiple problems implementing it. On one hand in this particular project the attributes were not an option, on the other I require the discriminator map to be in code for better maintainability (if you can not click on it, you will not maintain it); also, I found myself debugging the Injection of the resulting serializer very hard - please feel free to teach me better and share your implementation.\npublic function fromArray(array $row): Achievement { $identifier = $data[\u0026#39;identifier\u0026#39;]; return match ($identifier) { self::ACHIEVED_OBEDIENCE_V2 =\u0026gt; new ObedienceAchievement($row[\u0026#39;contestIdentifier\u0026#39;], $row[\u0026#39;points\u0026#39;], $row[\u0026#39;ranking\u0026#39;], $row[\u0026#39;recordedAt\u0026#39;]), // historically there was no contest identifier in the past, however all contests before the change had the same identifier self::ACHIEVED_OBEDIENCE_V1 =\u0026gt; new ObedienceAchievement(\u0026#39;Obedience Trail 2023\u0026#39;, $row[\u0026#39;points\u0026#39;], $row[\u0026#39;ranking\u0026#39;], $row[\u0026#39;recordedAt\u0026#39;]), default =\u0026gt; throw new InvalidArgumentException(\u0026#39;Unknown identifier: \u0026#39; . $identifier), }; } Event deserialization #Repository classes containing to instantiate entities from the database are sometimes quite big and messy. A cleaner solution for this problem that comes in handy with instantiating events from json or from a raw database row is using a normalizer. 6\nclass AchievementNormalizer implements NormlizerInterface, DenormalizerInterface { private const ACHIEVEMENTS_MAP = [ Achievement::ACHIEVED_OBEDIENCE_V1, Achievement::ACHIEVED_OBEDIENCE_V2 =\u0026gt; ObedienceAchievement::class, Achievement::ACHIEVED_DOG_LICENSE_V1 =\u0026gt; DogLicenseAchievement::class, ]; public function __construct(private ObjectNormalizer $normalizer) {} public function normalize($object, string $format = null, array $context = []): array { $this-\u0026gt;normalizer-\u0026gt;normalize($object, $format, $context); } public function denormalize($data, string $type, string $format = null, array $context = []): Achievement { $identifier = $data[\u0026#39;identifier\u0026#39;] ?? throw new InvalidArgumentException(\u0026#39;No identifier found\u0026#39;); if ($identifier == \u0026#39;*the super old identifier we do barely support*\u0026#39;){ return new DepricatedAchievement($identifier); } $type = self::ACHIEVEMENTS_MAP[$identifier] ?? throw new InvalidArgumentException(\u0026#39;Unknown type: \u0026#39; . $identifier); return $this-\u0026gt;normalizer-\u0026gt;denormalize($data, $type, $format, $context); } public function supportsDenormalization($data, string $type, string $format = null): bool { return $type === Achievement::class; } public function getSupporedClass(): array { return[Achievement::class =\u0026gt; true]; } } Having a special normalizer for this enables the developer to have a clean repository class, but still provides a place to hook into the deserialization process, set defaults for old fields, or throw exceptions for unknown fields. The discriminator map is hold in code, so any code editor can jump to the events, and back.\nA test could look like:\npublic function testSerializeAndDeserialize(): void { $achievement = new ObedienceAchievement(\u0026#39;Obedience Trail 2023\u0026#39;, 100, 1); $encodedAchievement = $this-\u0026gt;serializer-\u0026gt;serialize($achievement, \u0026#39;json\u0026#39;); $achievementArray = json_decode($encodedAchievement, true); $this-\u0026gt;assertArrayHasKey(\u0026#39;identifier\u0026#39;, $achievementArray); $this-\u0026gt;assertEquals(Achievement::ACHIEVED_OBEDIENCE_V2, $achievementArray[\u0026#39;identifier\u0026#39;]); $deserialized = $this-\u0026gt;serializer-\u0026gt;deserialize($encodedAchievement, Achievement::class, \u0026#39;json\u0026#39;); $this-\u0026gt;assertInstanceOf(ObedienceAchievement::class, $deserialized); } Also, a test that grabs all achievements from the directory folder and checks if they can be deserialized should be added to ensure that the map is always updated when a developer adds a new achievement.\nConclusion #Event Sourcing is a great pattern, and for certain use cases the best solution. The implementation can be quite tricky, but if the team works through the current and future challenges, the pattern can be a great addition to the project.\nHappy Coding :)\nImplementation idea and code snippets are inspired by the book \u0026ldquo;Implementing Domain-Driven Design\u0026rdquo; by Vaughn Vernon.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAudit Trailing via event sourcing\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPostgres JSONB\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLaravel Morph Maps\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSymfony Discriminator Map\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSymfony Normalizer\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"28 April 2024","permalink":"/posts/2024-04-event-sourcing/","section":"Posts","summary":"Event Sourcing is a software pattern for stateful entity management.","title":"Event Sourcing for long living projects"},{"content":"","date":null,"permalink":"/tags/software-pattern/","section":"Tags","summary":"","title":"Software Pattern"},{"content":"","date":null,"permalink":"/tags/symfony/","section":"Tags","summary":"","title":"Symfony"},{"content":" Feature Flags are both - a hit on the bullshit bingo and case for a trigger warning. This blog post is about how they can help, and how to use them in Gitlab. About Feature Flags #Feature flags are a way to control the reachability of a feature in your application. For a basic implementation a simple if-else statement can be used.\n// todo: set to false before release if (false) { $this-\u0026gt;someGreatNewFeature(); } else { $this-\u0026gt;oldFeature(); } In a more advanced solution, there might be a setting in a config, or even an environment variable to toggle a feature on or off. Again the next step might be an if statement depending on the user who is logged in, if they have a certain permission or \u0026ldquo;developer cookie\u0026rdquo;. But the most recent approach is to use a Feature Flag Service with an Api call to toggle it without a deployment.\nWhy Feature Flags? #Feature Flags are a development tool that is very easy to sell. Business loves it, as they can see the new features before they are completely released; Quality Assurance loves it, as they can test the new features without big hassle with production data; database enthusiasts love it, as they can see the data behavior and performance in an early stage; and release managers love it, as they can release the new feature step by step, maybe starting with a small group of users who are a selected, well known, edge case free group of users.\nThere is a new epic to be released, and the mvp only satisfies a fraction of the possible users - feature flag can be the tool to control the continuous release of the epic to more and more users. Unsure if the release will work well? Only redirect a small percentage of the users to the new feature, and see if exceptions are hitting the monitoring, and roll back if necessary. Not sure if the build is even useful? Only release it to half the users and see which groups results in better KPIs ( A/B Testing). Two systems deployed separately with the same code and new features should only be released to one of the systems? Feature Flags again can solve the problem. Also there are different kind of Feature Flags - from a certain point of view a permission system is a feature flag. Some users may have access to a feature, that stay hidden for others. 1\nRed Flag Feature Flags? #Feature flags come with downsides. The most obvious is the introduction of technical dept. Every Feature Flag introduced in the code is on a certain level an if statement with a guaranteed future removal. At some point the feature is activated for all users, or removed completely.\nWith that planned obsolescence, there is added complexity. The simpler the feature flag is designed, the bigger the hassle to remove it, while on the other hand any work in designing nice feature flag mechanism is also work put into technical dept. At one point people might ask \u0026ldquo;What code is currently running?\u0026rdquo;, \u0026ldquo;Is that feature now used by everyone?\u0026rdquo;, \u0026ldquo;Where did we put that flag again?\u0026rdquo;, \u0026ldquo;Why does that work for Jeff, and not me?\u0026rdquo;, \u0026ldquo;That worked on a different environment!\u0026rdquo;. Inconsistency is never a good thing, and Feature Flags are a way to introduce it 2.\nFeature Flags are a release tool, not a configuration tool. They should be short lived, used for a specific purpose, and keep in mind you always have to clean after them. And I repeat myself, they are short lived (days or weeks) 3\nFeature Flags in Gitlab #Depending on the User Case, different choices in Technology should be made. For a permission system there are better solutions that anything that calls itself feature flag, and for A/B testing many Feature Flag libraries are not enough focused on metrics.\nIn my Use Case I was looking for a simple implementation, an accessible overview of the current feature flags, and a way to control the feature flags by user or context without a deployment. Gitlab offers an Unleash Hosting which served my needs, bonus points to automatically track and display usages of feature flags in the code, and not tracking a lot of metrics I don\u0026rsquo;t need.\nAdding Gitlab Feature Flags with the stupid questions answered #All together Gitlab Feature flags are easy to implement, and if you can avoid typos in the feature flag definition I am confident you can make it around two hours faster than I was ;)\nAdding the Unleash Client #**What is Unleash? ** Unleash is the Feature Flag Service Gitlab uses. Even the self-hosted Gitlab offers the Unleash API to control Feature Flags that you can easily configure in the Gitlab UI. It is also possible to host Unleash without Gitlab.\nI found the PHP Client more versatile than the Symfony Client 4. While digging through the Unleash Client I found clean written, supporting a lot of the Unleash API, and a very good documentation. Gitlab does not support all of the possible Features, which I consider as a good thing, as it keeps the Feature Flags simple and easy to use.\nFor the implementation the Unleash Docs are great help 5. Mind that the AppName is the Gitlab Environment.\npublic class FeatureFlagService { private Unleash $unleash; private UnleashContext $context; public function __construct() { // configs can be found in the Gitlab GUI $this-\u0026gt;unleash = UnleashBuilder::createForGitlab() -\u0026gt;withInstanceId(\u0026#39;H9sU9yVHVAiWFiLsH2Mo\u0026#39;) // this is an api key, keep it secret -\u0026gt;withAppUrl(\u0026#39;https://git.example.com/api/v4/feature_flags/unleash/1\u0026#39;) // url to unleash api -\u0026gt;withGitlabEnvironment(\u0026#39;Production\u0026#39;) // this is the environment name in Gitlab -\u0026gt;build(); $this-\u0026gt;context = new UnleashContext(); } public function isEnabled(string $feature, bool $default = true): bool { return $this-\u0026gt;unleash-\u0026gt;isEnabled($feature, $this-\u0026gt;context, $default); } public function setUser(string $id): bool { return $this-\u0026gt;context-\u0026gt;setCurrentUserId($id); } } Some words on the Context #The most interesting part of the Unleash Client is the Context. The Context holds the information about the user, as Feature Flags usually close to the user and therefore in the front end. But from data perspective it can be more interesting context to enable features on a subset of the entities. Use Cases for this are some kind of metrics, or the replacement of a feature set with a new solutions in different service.\nUsing the Feature Flags #The Service can be injected into the Authentication Middleware to set the User, and then used in the Controller to check if the Feature is enabled.\nclass NewController { public function get(Request $request, FeatureFlagService $featureFlagService) { $featureFlagService-\u0026gt;setUser($request-\u0026gt;getUser()); if (!$featureFlagService-\u0026gt;isEnabled(\u0026#39;new-feature\u0026#39;)) { return new JsonResponse(\u0026#39;Feature not enabled\u0026#39;, 404); } return $this-\u0026gt;newFeature(); } } Gitlab UI and First Test / Troubleshooting #This part is trivial, Gitlab offers a nice documentation of the GUI and it is mostly self-explanatory. 6 The interface allows the developer to define a Feature Flag, toggle it usages, limit it to a certain user or a predefined user group, and to see the usages of the Feature Flag in the code. No additional metrics are tracked.\nWith the first feature tested, it might work out of the box. If it doesn\u0026rsquo;t work, check if the Feature Flag is defined in the Gitlab UI and the spelling matches the one in the code. To check if Gitlab is reachable and the credentials are working, the Unleash API can be called directly.\ncurl -L -X GET \u0026#39;https://git.example.com/api/v4/feature_flags/unleash/1/client/features\u0026#39; \\ -H \u0026#39;Accept: application/json\u0026#39; \\ -H \u0026#39;Authorization: H9sU9yVHVAiWFiLsH2Mo\u0026#39; Or the still somewhat supported legacy API that does use a different Header\ncurl -L -X GET \u0026#39;https://git.example.com/api/v4/feature_flags/unleash/1/client/features\u0026#39; \\ -H \u0026#39;Accept: application/json\u0026#39; \\ -H \u0026#39;UNLEASH-INSTANCEID: H9sU9yVHVAiWFiLsH2Mo\u0026#39; Clean up your Test Flags #Conclusion #Feature Flags are a powerful tool to control the release of new features, and the experience to use such a tool with such an easy set up makes it tempting to just experiment with it.\nHappy Coding!\nTypes and usages of Feature Flags\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDanger of Feature Flags\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBest Practices\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPhp Unleash Client\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nUnleash Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGitlab Feature Flags Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"5 March 2024","permalink":"/posts/2024-02-feature-flags/","section":"Posts","summary":"Feature Flags are both - a hit on the bullshit bingo and case for a trigger warning.","title":"Gitlab Feature Flags (for Backends)"},{"content":"","date":null,"permalink":"/tags/queue/","section":"Tags","summary":"","title":"Queue"},{"content":" How does the Symfony Messenger Component work; How can I hook into the process; and how can I use it for my own needs? Symfony Messages and Symfony Events #Coming from Laravel, and knowing how Laravel handles Events, I hat quite some bits to learn when I dived into the Symfony world 1. The most obvious change is while Laravel has Events, Symfony has Messages and Events.\nThe Symfony Events are synchronous, and are used to communicate between different parts of the application 2. This simple property makes it easy to decide if an event or a messages can solve your problem, events are the better choice if you need the result of the event to be communicated back, or if you don\u0026rsquo;t have the time/thread requirements to implement a queue. This Post will not Cover Events, but Messages only.\nStepping through Symfony Dispatcher and Consumer #Frameworks can seem magical in the beginning, but the more a developer knows about their inner workings, the better it can be used. If a developer is aware of the posible hooks and tricks very often very easy solutions for common problems can be implemented. To discover a framework, I go for a scribbled test and the debugger. In this case I wanted to know how the Symfony queue is consumed, and so I dispatched a command using a dependency injected CommandBus and stepped into every function on my way to my command handler.\nDispatching a job and adding Stamps #The first step leads to the Symfony\\Component\\Messenger\\MessageBusInterface, which leads to three possible Symfony implementation, which might add context but all end up in the same Symfony\\Component\\Messenger\\MessageBus::dispatch() function. The dispatch method also allows to add Stamps, little pieces of meta information about the Message. The dispatch function then creates a Symfony\\Component\\Messenger\\Envelope, which is a wrapper for the Message and the Stamps.\n✉️ I\u0026rsquo;ll give you a moment to be amazed by the naming - because I find it so cute! If you want a piece of your code to know some bits of information and act upon it, you put that info in an envelope, and than attach some stamps on it; the framework will look at the stamps and know how to route it to the right piece of code 💌. The Stamps are also a way to transport context over to the worker. One use case could be tracing an entity through your application.\nMiddlewares #Still in the dispatch methods, the Envelope is passed to the MiddlewareStack. The MiddlewareStack is a collection of Classes following the Pipeline Pattern. Pipeline Pattern is a way to execute a list of operations on a given input, where the result of each of the operations is passed to the next operation. In this case the input is the Envelope, and each Middleware adds or acts upon the mentioned Stamps; e.g. if the envelope needs to be sent (and where), if it failed, or if it\u0026rsquo;s received and needs to be handled.\nThe Middlewares are walked through in the same order both when the message is sent to a queue and when the message is consumed from a queue. The order of the Middlewares is important, the default order of the implemented Symfony Middlewares is:\nTraceableMiddleware: which traces and tracks the execution of the middlewares AddBusNameStampMiddleware: which adds the name of the bus to the message AddDispatchAfterCurrentBusMiddleware: messages with a DispatchAfterCurrentBusStamp are handled once the current dispatching is fully handled. FailedMessageProcessingMiddleware: If the Message doesn\u0026rsquo;t have the ReceivedStamp but a SentToFailureTransportStamp, it adds the ReceivedStamp to ensure the envelope is not sent to the failing transport again. Your own collection of Middlewares: Could add Logging Context, Metrics, Tracing Information\u0026hellip; SendMessageMiddleware: if there is no ReceivedStamp and routing is configured for the transport, this sends messages to that transport HandleMessageMiddleware: calls the message handler(s) for the given message. Simplified example of one of the Middlewares SendMessageMiddleware 3:\nclass SendMessageMiddleware implements MiddlewareInterface { public function handle(Envelope $envelope, StackInterface $stack): Envelope { $sender = null; // check if the envelope is already received if ($envelope-\u0026gt;all(ReceivedStamp::class)) { // it\u0026#39;s a received message, do not send it back } else { // send the message to all senders foreach ($this-\u0026gt;sendersLocator-\u0026gt;getSenders($envelope) as $sender) { $envelope = $sender-\u0026gt;send($envelope-\u0026gt;with(new SentStamp($sender::class))); } } // if there is no sender, call the next middleware if (null === $sender) { return $stack-\u0026gt;next()-\u0026gt;handle($envelope, $stack); } // message should only be sent and not be handled by the next middleware return $envelope; } } SideQuest-Question: How are the Middlewares set up and how are custom Middlewares added? Symfony does a great job in dependency injection. In the config/packages/messenger.yaml is the place to add additional Middlewares. To also understand how the Middlewares are configured, I dug a bit deeper in the Symfony/Component/DependencyInjection/Loader/Configurator/messenger.php file. Here are the defaults set for all mentioned Middlewares. Custom Middlewares are read from the config in the FrameworkBundle/DependencyInjection/Configuration.php::addMessengerSection(). And looking at the code, that\u0026rsquo;s a story for another post.\nConsuming Messages #Assuming the SendMessageMiddleware sent the message to a Transport of your choice, the message was in a queue which picked it up is now calling a console command messenger:consume which is a Symfony\\Component\\Messenger\\Command\\ConsumeMessagesCommand. This instantiates a Worker, which Messenger/Worker which performs the actual consumption of an Envelope.\nA simplified version of the Worker 4:\nprivate function handleMessage(Envelope $envelope, string $transportName): void { // throughout the whole process, events are dispatched to allow to hook into the process $this-\u0026gt;eventDispatcher?-\u0026gt;dispatch(new WorkerMessageReceivedEvent($envelope, $transportName)); // the message is dispatched to the bus, which calls the middlewares // the ReceivedStamp is added $envelope = $event-\u0026gt;getEnvelope(); $envelope = $this-\u0026gt;bus-\u0026gt;dispatch($envelope-\u0026gt;with(new ReceivedStamp($transportName), new ConsumedByWorkerStamp())); $this-\u0026gt;ack(); } So here the Middlewares are called again, but this time the HandleMessageMiddleware is called, in which the Handler(s) are determined and called. The HandlerLocator uses mostly a config to determine the Handler (but I guess an Attribute would be possible too). Foreach Handler the HandledStamp is added to the Envelope, to ensure the message is not handled multiple times.\nConclusion #Symfony Messenger is a great tool to decouple parts of your application. Looking under its hood, it is a well-designed tool, it\u0026rsquo;s awesomely named, and it\u0026rsquo;s more versatile than I personally found the Laravel solution to the same problem. The middlewares are easy and spot on in their utility. I am looking forward to using it in future blog posts.\nHappy Coding :)\nHow Laravel Queues work\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSymfony Events\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSymfony Messenger SendMessageMiddleware\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSymfony Messenger Worker\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"1 February 2024","permalink":"/posts/2024-01-symfony-queues/","section":"Posts","summary":"How does the Symfony Messenger Component work; How can I hook into the process; and how can I use it for my own needs?","title":"Symfony Messenger Component step by step"},{"content":" PHP attributes are a great addition to the language. But how are they used, can I use them, and what are Use Cases? What Attributes can do #Attributes are one of the greatly expected features of PHP 8.0. They are a way to add metadata to classes, methods, or properties/ constants. The feature itself is no new idea PHP came up, but many other languages already utilize Attributes or Annotations (as many languages call them) - and therfore we can learn from Frameworks like Spring to learn how to use Attributes 1.\nAttributes are awesome! But as you will se in the implementation examples, they are a bit of magic. I personally consider them less \u0026ldquo;magic\u0026rdquo; than Laravel\u0026rsquo;s partially visible Providers, or Symfonie\u0026rsquo;s yaml config files. Implementation Example of Attributes as Listener Config #Depending on the Framework there are implementations for Listener Wiring, Symfony already switched the .yaml config for Attributes. The following example is a simplified version of this Idea.\nDev-User Perspective first, what should be achieved? Possible Solutions to add the attribute to the class and implementing a function on(EventInterface $event): void method. In that case the Attribute should target the class.\n#[ListensTo(UserCreated::class)] readonly class UserListener { public function on(EventInterface $event) { ... } } But we can also target the method, which would be a bit more verbose, but impractical if there are multiple events that require actions by multiple methods.\nreadonly class UserListener implements EventListenerInterface { #[ListensTo(UserCreated::class)] public function onUserCreated(UserCreated $event) { ... } } The Attribute itself is implemented as class. Here the implementation for the Listener on the class. As it should be possible to register more than one event on the listener, the Attribute is marked as IS_REPEATABLE.\n#[Attribute(Attribute::TARGET_CLASS| Attribute::IS_REPEATABLE)] readonly class ListensTo { public function __construct(public string $event) {} } A list of possible targets are listed in the Attribute class 2:\nTARGET_CLASS = 1 Marks that attribute declaration is allowed only in classes TARGET_FUNCTION = 2 Marks that attribute declaration is allowed only in functions TARGET_METHOD = 4 Marks that attribute declaration is allowed only in class methods TARGET_PROPERTY = 8 Marks that attribute declaration is allowed only in class properties TARGET_CLASS_CONSTANT = 16 Marks that attribute declaration is allowed only in class constants TARGET_PARAMETER = 32 Marks that attribute declaration is allowed only in function or method parameters TARGET_ALL = 63 Marks that attribute declaration is allowed anywhere IS_REPEATABLE = 64 Notes that an attribute declaration in the same place is allowed multiple times To read out the attributes, the Reflection API is used. In this case a Method is called during the container build.\npublic function register(EventListenerInterface $listener): void { $reflection = new ReflectionClass($listener); foreach ($reflection-\u0026gt;getAttributes(ListensTo::class) as $attribute) { /** @var ListensTo $listensTo */ $listensTo = $attribute-\u0026gt;newInstance(); $this-\u0026gt;listeners[$listensTo-\u0026gt;event][] = $listener; } } This was the point where I was amazed how easy this was! Of cause using the Reflection API always feels like performing black magic, but in this example I find it way more readable than some configs.\nReplacing configs with Attributes # Symfony requires configs for Dependency Injection, which could be replaced by a Spring inspired [#Autowired] Attribute. The mentioned Listener Wiring could be replaced by a [#ListensTo] Attribute. The [#Route] Attribute could replace the routes.yaml config file (or the routes/api.php in Laravel). There are already some implementations for this 3. The [#Handels] Attribute could map Commands to CommandHandlers Validation #Validation using Attributes comes in so easy, readable, and minimalistic. Imagine a Request could look like this:\nclass UserCreateRequest { #[Required()] public readonly string $name = null; #[Min(1)] #[Max(10)] public readonly string $numberBetweenOneAndTen = 0; #[Pattern(\u0026#34;^[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}$\u0026#34;)] public readonly ?string $ipAddress = null; ... } Other use cases # [#Example] Attribute to give an example, but maybe also to generate mini fixture [#Dataset] Provide a dataset for a test [#SupressWarnings] could replace the phpstan-ignore comments Conclusion #Attributes are a great addition to PHP. I am looking forward to see how they will be used in the future, and hope they will replace some configs, classes, and make code more readable.\nHappy Coding :)\nSpring Framework - Annotations\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nVery good Article about Attributes\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRoute Attributes for Laravel\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"20 January 2024","permalink":"/posts/2024-01-using-php-attributes/","section":"Posts","summary":"PHP attributes are a great addition to the language.","title":"Dive into PHP Attributes"},{"content":"","date":null,"permalink":"/tags/php/","section":"Tags","summary":"","title":"PHP"},{"content":" \u0026ldquo;It is better to be vaguely right than exactly wrong.\u0026rdquo; - Carveth Read. While the trend goes in a direction to put a metric on everything to drive decisions, most teams I have worked with are still in the beginning of this journey. 1\nUsing Data to Ignite Action #In one of my favorite talks from DevOpsDays 2 Julie Starling is talking here about using data to drive conversations.\nOn of the key takeaways for my was the Idea of Probabilistic Forecasts. This means using past data to make a prediction about the future with the awareness that the prediction is not 100% accurate, focusing on a probability in a range. For example \u0026ldquo;There is a 80% chance of delivering 10 or more Story Points this Sprint\u0026rdquo; (How much will we do?); or \u0026ldquo;There is a 90% chance of finishing 10 Story Points in the next 14 Days or less\u0026rdquo; (When will we get it?).\nMonte Carlo Method #Monte Carlo Method: Builds a model of possible results by using the Law of greater Numbers; OR Simulations to calculate the probability of a range of outcomes, which somewhat if we run a Simulation based on our last 10 Sprints, x% of the time we would have delivered a minimum of y Story Points in time. The accuracy of the prediction increases with the increased number of inputs - although in a development environment with experiments, changes in tech stacks, or changes in team composition, less inputs might be sometimes more accurate.\nMonte Carlo might not include correct risk dependencies. If one ticket fails, dependent might or might not fail too. Using Data to Drive Conversations #Julie uses Monte Carlo Simulations multiple times throughout the Sprint, to get a better and better prediction - and to react at the earliest possible time. The moment the probability of delivering the minimum Story Points in time drops, or the expected date to finish all work items is after the deadline, there is a need for a conversation. This Conversation might include a change of expectations or a change of scope.\nThe Flaw of Averages (by Sam L. Savage) #This book is a great starting point to understand why Averages are not the best metric to plan actions. 3\nPlans based on average assumptions are wrong on average. Every developer knows the struggle to explain to PO that 10 Tickets with all the same estimation of one week will only be on average be delivered in a week, and therefor behind schedule half of the time.\nThe weak and strong form of the Flaw of Averages #The weak form of the Flaw of Averages states is forecasting a result based on a single number instead of the distribution of outcomes. One kinda german example for this would looking at the average win of a lottery without considering the average cost or the probability distribution.\nThe baseline to avoid this is \u0026ldquo;View uncertainty as a shape, not a number.\u0026rdquo; (Normal distribution, even distribution, \u0026hellip;)\nThe strong form of the Flaw of Averages states that the average inputs do not equal the average outputs. The output of the average team is not equal to average output of all teams.\nThe seven deadly sins of Averages # The average often does not exists (like the 1.5 child people have) The average task length is not the average project length Diversification works for projects management: If you add more independent tasks, the form of the distribution histogram will approach a bell curve. Be clear if your risk depends on restriction (how many people can work on a task) or on opportunity (how much will performance increase from refactor). Optionality - can you remove costs in case of losses? Cost of average demand is not the average cost. Things may happen by chance =\u0026gt; we are just doing hypothesis testing. Flaws of Extremes: Budgeting for risks becomes exponentially expensive. Current State of Error #After this theory, I am still in the process of implementing this in my team. Moving away from the simple calculation of Averages to complex modelling while spending enough time in this to make it a valid experiment, and not falling for sunk cost fallacy or spending more time on it than the team would benefit from it.\nI wish I could write more about how this changed my team, or how we implemented it; but this is my current state of error.\nKeep Coding :)\nLogic - DEDUCTIVE AND INDUCTIVE\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDevOpsDays Amsterdam 2023\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFlaw Of Averages\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"21 November 2023","permalink":"/posts/2023-11-using-data-to-ignite-action/","section":"Posts","summary":"\u0026ldquo;It is better to be vaguely right than exactly wrong.","title":"Using data for Sprint Planning"},{"content":" Effective communication is essential in software development. As per Conway\u0026rsquo;s Law, the structure and architecture of a software system are influenced by the communication patterns and structures within the organization. Conways Law # Conways Law: Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization\u0026rsquo;s communication structure. [^conwaysLaw] Conway\u0026rsquo;s Law means that the communication structures and patterns within the team will impact the design and architecture of the software system a set of Developer Teams is developing. If the team is structured in a way that promotes collaboration and communication between different members and departments, the resulting software system will likely be well-structured and modular, with clear interfaces between different components. On the other hand, if the team is siloed and communication is poor, the software system may end up being poorly organized and difficult to maintain. Silos can occur when teams are organized around a specific product and do not have the chance to collaborate with other teams or consider reuse of existing work.\nWays to improve communication #There are many ways to improve the communication between teams, some will be outlined here.\nArchitecture Decision Records #Tests, comments, and human readable code are in my experience the most read and used documentation. But still, there are situations in which the way the code is written only makes sense in the context in which the decision was made. Often enough, that bad looking class has a reason to exists in that way - and even if the explanation is \u0026ldquo;because of historic reasons\u0026rdquo;, it something in a lot of codebases has to be communicated verbally. Especially in cases, where multiple teams work on the same code base this can be a problem - that is why Architecture Decisn Records (ADR) can fill that communication gap.\nHype or Established? The concept of ADRs was coined in 2011 1, was added in the thoughtworks tech radar in 2016 2, and is now in usage in multiple tech companies (often if the teams are very independent). The tools on the other hand are often open source, sometimes still working, and rarely maintained well 3. My personal two cents are: Architecture Decision Records are established, but the tools are often more hyped that practical.\nExample of an ADR:\n# Use Markdown for Architecture Decision Records ## Context and Problem Statement We want to record architectural decisions made in this project. The following requirements apply: - The format should be human readable and easy to write. - The files should be inside the code base, such that a new decision can be made using a pull request. - The format should enable references to older decisions or files in the code base. Some established solutions: * [MADR](https://adr.github.io/madr/) - Some simple Markdown solution * Michael Nygard\u0026#39;s template [^techRadar] – Markdown with Status and Consequences * The Y-Statements - \u0026#34;we decided for XXX and against ZZZ to achieve A and B, accepting that C\u0026#34;. * Formless – No conventions for file format and structure ## Decision Outcome The benefits of Michael Nygard\u0026#39;s template are the Consequences, so a section to update information on the decision, e.g. by now a new feature has replaced this decision, but this one customer still needs it, so it is marked deprecated. This contradicts the idea that these files a immutable, but here I am still coding PHP so what do I know. ## Status I wrote a blog post, will have hold a presentation in my current company, and see what happens. ## Consequences // KPIs as a common goal #To fight Silos, one option is to give teams common, meaningful KPIs and missions that contribute towards larger goals, encouraging collaboration and avoiding the siloing of teams. Communication is also key to breaking down silos, and teams should seek opportunities to work together and learn from each other\u0026rsquo;s areas of expertise 4.\nTeam Structure #Silos can develop in software development when teams or departments become isolated and focused only on their own goals and objectives, without considering how their work impacts the rest of the organization. This can lead to a lack of collaboration, poor communication, and a fragmented approach to software development.\nShared accountability: Cross-functional teams are accountable for the success of the project as a whole, not just their individual tasks. Improved communication: Cross-functional teams encourage open communication between team members from different disciplines, which can help to break down silos by promoting a culture of knowledge sharing and collaboration. Shared knowledge: Cross-functional teams bring together different areas of expertise, which can help to reduce silos by sharing knowledge and skills across the team. Faster decision-making: Cross-functional teams can make faster decisions as there is no need to wait for approval from different departments. Also switching around the teams can improve communication and collaboration, as well as knowledge sharing.\nCommon Meetings #A possible Agenda may vary from meeting to meeting, but the goal is to have a common meeting where all teams can participate and exchange knowledge.\nLatest Features: A meeting in which each team presents the latest features they have implemented, including the added dependencies or patterns. Latest Wins: Talking about patterns which have proven useful, Code styles that made things easier to read, or anything else that has been a win for the team and can be a win for others. Latest Fails: Having a shared Post Mortem of a failed feature or a failed deployment can help to avoid the same mistakes in the future. New Ideas: A meeting in which a new Idea is pitched to be discussed and feedback is given. Social: The goal of such a meeting may be nothing more than social interaction, just having a pub quiz as only agenda point can be relaxing from time to time. Conclusion #There are ways to improve Team communication, and the way the communication is organized, how hygienic and structured it is, can have a huge impact on the software system that is being developed. I would not dare to enforce long, daily or weekly meetings on developers who prefer sitting in their cellar and coding, because communication does not need to be a meeting, nor a formal setup with 50 people.\nHappy communicating!\nMichael Nygard: Architecture Decision Records\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThoughtworks Tech Radar\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nADR Tools\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBecoming a Great Engineering Manager and Balancing Synchronous and Asynchronous Work - InfoQ Podcast\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"16 April 2023","permalink":"/posts/2023-04-communicating-between-teams/","section":"Posts","summary":"Effective communication is essential in software development.","title":"Communication between different teams working on the same codebase"},{"content":"","date":null,"permalink":"/tags/testing/","section":"Tags","summary":"","title":"Testing"},{"content":" Using Tests to verify the type and nullable correctness of an Open Api file is one way to ensure a usable documentation (if the file cannot be generated). This blog post is the result of a use case on testing requests and responses to Open Api conformity. Use Case #PHP Apis are famous for their inconsistent typing and the lack of respect of nullable values. This is a problem, because other languages do (thankfully) not cast any value to any other value without complaining neither on compile time nor on run time. PHP Developer have nether the less started to use Open Api files to document their Apis - and often enough included their typing inconsistency in their Open Api file. While some are in the great position to generate the Open Api file, others might require a handwritten and maintained Open Api file (or a combination of both).\nThe Base Assumption therefore is: Developers have to maintain the Open Api File by hand - or as user story: As a Developer, I want a Test to fail if the Open Api file is conflicting with the actual Api.\nMise en place: Reading and validating the Open Api File #Fortunately, there is at least one great library that can read an Open Api file and hold it as an object, as well as writing it to a file 1.\nThe Library does a great job at making the Open Api file accessible in PHP. In case a third party is consuming the Open Api File (like readme.io), this also enables you to write a Command that will generate a fresh open Api File with resolved cross file references (in case you want to generate parts of your Open Api file ;) ).\nOne other library that I will use in this post is using the above to validate Requests and Responses against the Open File. 2\nRequest Validation #Easy steps first: The Request usually does not cause any problems on PHP Apis. Any value that comes it, and should be a boolean but is a string, a number, or anything else will be easily converted to a boolean. Although some Api consumers might not share PHPs view of an empty string as falsy value.\nUsing defined data providers / test sets #If there are already defined test sets to be used in the API, and those are used by the developer for new features ( maybe even enhanced regularly), it is easy to use those test sets to validate the Open Api file.\nSo a simple tests would just use the same data set used for testing the Api (or Api validation) and validate the test request data against the Open Api definition 2. Any changes made to the test files (e.g. for a new feature) or an updated Test file will automatically be validated against the Open Api file.\nPRO\nEasy to implement Easy to maintain / debug Deterministic CON\nThe tests are only as good as the test data set Contract Testing using Open Api as Contract # Contract Testing: Contract testing is a methodology for ensuring that two separate systems (such as two microservices) are compatible and can communicate with one other. It captures the interactions that are exchanged between each service, storing them in a contract, which then can be used to verify that both parties adhere to it. [^contractTesting] So, the idea is to assume the Open Api is the Contract between the Api and the Api Consumer. The Consumer should be able to send any kind of request that conforms the Open Api, and the Api should be able to respond.\nUsing e.g. the Laravel Generator, writing a Request Generator is not hard.\n/** * @param \\cebe\\openapi\\spec\\Schema|\\cebe\\openapi\\spec\\Operation $schema * @param $pointer */ public function mockData(Schema $schema, $pointer = \u0026#39;root\u0026#39;) { if (! empty($schema-\u0026gt;oneOf) || ! empty($schema-\u0026gt;anyOf)) { $options = $schema-\u0026gt;oneOf ?? $schema-\u0026gt;anyOf; $randomIndex = $this-\u0026gt;faker-\u0026gt;numberBetween(0, count($options) - 1); return $this-\u0026gt;mockData($options[$randomIndex], $pointer . \u0026#39;-\u0026gt;\u0026#39; . $randomIndex); } if (! empty($schema-\u0026gt;allOf)) { return $this-\u0026gt;mockAllOf($schema-\u0026gt;allOf, $pointer); } return match ($schema-\u0026gt;type) { Type::INTEGER =\u0026gt; $this-\u0026gt;faker-\u0026gt;numberBetween($schema-\u0026gt;minimum, $schema-\u0026gt;maximum), Type::NUMBER =\u0026gt; $this-\u0026gt;faker-\u0026gt;randomFloat(4, $schema-\u0026gt;minimum, $schema-\u0026gt;maximum), Type::BOOLEAN =\u0026gt; $this-\u0026gt;faker-\u0026gt;boolean(), Type::STRING =\u0026gt; $this-\u0026gt;mockString($schema), Type::ARRAY =\u0026gt; $this-\u0026gt;mockArray($schema, $pointer), Type::OBJECT =\u0026gt; $this-\u0026gt;mockObject($schema, $pointer), default =\u0026gt; throw new \\Exception(\u0026#39;Unsupported datatype \u0026#39; . $schema-\u0026gt;type . \u0026#39; at \u0026#39; . $pointer), }; } I am looking forward to publish the code as soon as I can. For now, this is all I dare to show, at least the learning of handing down the pointer to give accurate error messages in case of failure is some value. The Types and Schema are used using the Open Api Library 1, while the Faker is the Laravel Generator 3.\nPRO\nMight test the Api through every option eventually Can point out bugs in the code beyond the Open Api file verification CON\nNon-deterministic =\u0026gt; Make sure the failing messages contain the exact request that failed! Not straight forward to implement Might need constant attention as it might return errors weeks after a bug was introduced Has limits The Limits: E.g Laravel Validation goes far beyond the Open Api file. Validations like \u0026ldquo;exits in database\u0026rdquo; are near to impossible to implement in the Open Api file; validations like \u0026ldquo;required if another field is set\u0026rdquo; are possible, but working with the OneOf, AnyOf, AllOf causes more trouble down the road.\nResponse Validation #The Response Validation is more delicate, as this causes more problems for the Api Consumer - while Laravel Resources are especially frustrating to keep correctly typed; even other Frameworks have similar problems.\nThe same as for the Request Validation, the same applies for the Response Validation. This can either be the DataSets to test the Resources (if such datasets exist) or the Test Sets to test the Api can run on the response of a Controller. Of cause, using random generated input data, and then checking the resulting response would be the most complete way to test.\npublic function testOpenApiGetUserResponse() { $user = User::factory()-\u0026gt;create(); $response = $this-\u0026gt;get(route(\u0026#39;user.index\u0026#39;)); $response-\u0026gt;assertSuccessful(); $this-\u0026gt;assertValidAgainstOpenApi($response, \u0026#39;/users\u0026#39;); } /** * Assert that a Response is fits to a path in the specified Open Api File * * Debugging Hint fot the OneOfMany switch: * The Exception with more information why a sub schema failed is thrown in * vendor/league/openapi-psr7-validator/src/Schema/SchemaValidator.php */ protected function assertValidAgainstOpenApi( \\Illuminate\\Testing\\TestResponse $response, string $path, string $method = \u0026#39;get\u0026#39;, ): void { $result = ValidatorBuilder::fromYaml(config(\u0026#39;openapi.path\u0026#39;)) -\u0026gt;getValidator() -\u0026gt;validate($response-\u0026gt;baseResponse, $path, $method); $this-\u0026gt;assertTrue($result); } Conclusion #Don\u0026rsquo;t be the PHP Developer that Api consumers hate because their Open Api file feels like an inspiration for the typing in the Api Parameters and Responses. If you can not generate a correct Open Api file, write a test that will remind you to maintain it.\nHappy Coding :)\nRead and write OpenAPI 3.0.x YAML and JSON files and make the content accessible in PHP objects\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOpenAPI PSR-7 Validator\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFaker that Laravel uses as well\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"28 March 2023","permalink":"/posts/2023-03-testing-open-api-specs/","section":"Posts","summary":"Using Tests to verify the type and nullable correctness of an Open Api file is one way to ensure a usable documentation (if the file cannot be generated).","title":"Testing Open Api files"},{"content":"","date":null,"permalink":"/tags/laravel/","section":"Tags","summary":"","title":"Laravel"},{"content":" Casts are already a great feature of Laravel. They allow you to easily convert a value from the database to the scalar value actually needed. But in case of Arrays, especially in a Domain Driven Design context, the default Laravel Casts are reaching their limits. In this post, I want to celebrate the power of Laravel Custom Casts and how an implementation could look like. Json in relational Databases #There are different types of databases - most common in the Laravel ecosystem are relational databases. And they fulfill their purpose great - they hold structured, typed data; display relations between data; and are known by most developers, which means people know how to use them and how to optimise them. Still, sometimes the flexibility of Json objects is needed in a relational database - and although people love arguing about when to use a document database instead, there are reasons not to: Maybe the flexibility, a situation in which the developer is still drafting, or storing temporary data that is not meant to be analysed or queried 1.\nLaravel Casting #But if the decision was made and there is a json column in the database, how can it be used in the code? My personal favorite is to use a custom cast, so lets hop into this little deep dive on casts.\nThe Laravel documentation offers the Array cast as best practice for json columns, which would look like this 2:\nclass User extends Model { protected $casts = [ \u0026#39;notification_settings\u0026#39; =\u0026gt; \u0026#39;array\u0026#39;, ]; } The function Illuminate/Database/Eloquent/Concerns/HasAttributes::castAttribute, holds the gigantic switch case that calls the surprisingly simple code return json_decode($value ?? '', ! $asObject).\nWhat was stored as a json string in the database, is now decoded into an array - and now offers all the problems of arrays, being untyped, doomed for misuse, only understandable with examples no one will keep up to date. Or, we don\u0026rsquo;t cast it to an array, but to a value object (call it Data Transfer Object if you feel like it, but please don\u0026rsquo;t appreciate it to DTO\u0026hellip; please\u0026hellip;). This is supported by Laravel and mentioned in the Documentation, but from my point of view it is not practiced enough!3\nDefining a Value Object # Value Objects: Using objects instead of arrays has some benefits:\nThe object describes a thing in the domain - by giving it a name communication with developers and business gets easier. The type of the data is clear, so the developer can use the IDE to autocomplete the properties. The data is immutable, so it can\u0026rsquo;t be changed by accident. The data is valid as it is typed and can\u0026rsquo;t be changed to an invalid state. 4\nTo make a value object out of the json column, we need to define a class that holds the data and can implements the JsonSerializable trait. In this easy example that would not be necessary, but if the object gets bigger, this function ensures that the value object is serialized in the desired way. I also included a default using the constructor, it is not necessary as well, just a nice feature (if the Value Object is not replaced when the model is saved, the Database Value will still be null)\nuse JsonSerializable; use Illuminate\\Contracts\\Support\\Arrayable; class NotificationSettings implements JsonSerializable, Arrayable { public function __construct( public readonly bool $receivesAlerts = true, public readonly bool $receivesInfos = true, public readonly string $notificationTime = \u0026#39;daily\u0026#39;, ) { } public static function fromJson(string|null $value): self { if (!$value) { return new self(); } $decoded = json_decode((string) $value, true); return new self( new NotificationMessageTypeBooleanGroup($decoded[\u0026#39;receivesAlerts\u0026#39;]), new NotificationMessageTypeBooleanGroup($decoded[\u0026#39;receivesInfos\u0026#39;]), new NotificationMessageTypeBooleanGroup($decoded[\u0026#39;notificationTime\u0026#39;]), ); } public function jsonSerialize(): array { return [ \u0026#39;receivesAlerts\u0026#39; =\u0026gt; $this-\u0026gt;errors, \u0026#39;receivesInfos\u0026#39; =\u0026gt; $this-\u0026gt;successfulReceivedMessages, \u0026#39;notificationTime\u0026#39; =\u0026gt; $this-\u0026gt;successfulSendMessages, ]; } public function toArray(): array { return $this-\u0026gt;jsonSerialize(); } } Arrayable: The Arrayable interface is used to ensure that the value object can be converted to an array. This is a must if you use the Models toArray() function at any moment (which the framework does e.g. when using the Laravel Request without JsonResources) Casting the Value Object #Now the value object needs to be connected to the User Model using a custom Cast. The important thing is to implement the CastsAttributes interface, which requires the get and set methods. I decided to put most of the logic in the Value Object class, a valid and maybe more pattern based approach would be to put the logic in the Cast class.\nuse App\\Support\\ValueObjectsNotificationSetting; use Illuminate\\Contracts\\Database\\Eloquent\\CastsAttributes; class NotificationSettingsCast implements CastsAttributes { public function get($model, $key, $value, $attributes) { return NotificationSettings::fromJson($value); } public function set($model, $key, $value, $attributes) { return json_encode($value-\u0026gt;jsonSerialize(), JSON_THROW_ON_ERROR); } } Last step to make it work is to add the cast to the User Model:\nprotected $casts = [ \u0026#39;notification_settings\u0026#39; =\u0026gt; NotificationSettingsCast::class, ]; How the Cast is called by the Framework #Going back to the Illuminate/Database/Eloquent/Concerns/HasAttributes::castAttribute, if the switch case can not handle the default case, the NotificationSettingsCast is identified as isClassCastable, and it\u0026rsquo;s get method is called with $model the User Model, $key the name of the column, $value the value of the column, and $attributes the other attributes of the model as array. Vise versa, the set method is called when the model is saved, and the value object is serialized to json.\nBut wait, there is more! Other usages of Casts #Casts can also be used to fill \u0026ldquo;imaginary\u0026rdquo; columns, that are not stored in the database, but are calculated from other sources. For example calculating the current State of a model, based on the timestamps of the model (or the existince of certain Relations) can be performed by a Cast.\nBoolean Cast for Time Stamps #Often boolean values are stored as timestamps in the database, most common example would be the email_verified_at column. While the information when the email was verfiied is interesting, most times in the code only the fact it is not null is relevant.\nFor this use case, a parameter is passed to the cast, which is the name of the column that holds the timestamp.\nprotected $casts = [ \u0026#39;is_email_verified\u0026#39; =\u0026gt; DateToBoolenCast::class . \u0026#39;:email_verified_at\u0026#39;, ]; In this setting requires a Castable class to inject the parameter into the Cast class.\nuse Illuminate\\Contracts\\Database\\Eloquent\\Castable; class DateToBoolenCast implements Castable { public static function castUsing(array $arguments) { return new NullableEnumCast($arguments[0]); } } While the Cast class performs the actual casting.\nuse Illuminate\\Contracts\\Database\\Eloquent\\CastsAttributes; class NullableEnumCast implements CastsAttributes { public function __construct( private readonly string $column, ) { } public function get($model, string $key, $value, array $attributes): bool { return (bool) $model-\u0026gt;{$this-\u0026gt;column}; } /** * @param $model * @param bool|null $value * @return mixed */ public function set($model, string $key, $value, array $attributes): ?string { if ($value) { $model-\u0026gt;{$this-\u0026gt;column} = now(); } } } Conclusion #Casts are a powerful tool to extend the functionality of the Eloquent ORM. They can be used to define Value Objects, calculate states, or fix columns to a more readable type.\nHappy Coding :)\nIf you want to read about when to use json in a relational db\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLaravel Array Cast.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLaravel Custom Cast Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nValue Objects explained in Domain Driven Design in PHP by Buenosvinos\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"28 January 2023","permalink":"/posts/2023-01-laravel-custom-casts/","section":"Posts","summary":"Casts are already a great feature of Laravel.","title":"Laravel Custom Casts"},{"content":" Validations are great for ensuring that the data you receive is in the format you expect, while also handling a lot of edge cases (like ids that are not in the database). This ensures not only a fast failing of the request, but also gives the user (or front-end developer) a clear error message. Laravel offers great tools, in which I would like to dig deeper up to a final form of unintended usage - like Recursive Validations. Validation in Form Requests #A custom FormRequest can have a function rules() which returns an array of rules, which are used to validate the data. The magic behind this function includes the Validator class (Illuminate\\Validation\\Validator) which loops over all key-value pairs, resolves the corresponding Rule (like \u0026lsquo;min:2\u0026rsquo; into Rule::min(2)) and checks if they fail. The \u0026lsquo;old school\u0026rsquo; Rules are classes that implement a function passes() that will return a boolean whether the given data is valid or not; based on that a translated error message is added to an Error Bag (and depending on the ' stopOnFirstFailure\u0026rsquo; the loop continues 1.\nAll this happens by magic if correctly injected in the Controller Method.\n\u0026lt;?php declare(strict_types=1); namespace App\\Http\\Requests; use Illuminate\\Foundation\\Http\\FormRequest; use Illuminate\\Validation\\Rule; class OrderRequest extends FormRequest { public function rules() { return [ \u0026#39;name\u0026#39; =\u0026gt; [\u0026#39;nullable\u0026#39;, \u0026#39;integer\u0026#39;, \u0026#39;min:1\u0026#39;, \u0026#39;max:100\u0026#39;], \u0026#39;game_id\u0026#39; =\u0026gt; [\u0026#39;required\u0026#39;, \u0026#39;exists:games,id\u0026#39;], // mind, that the Rules can be called as static methods \u0026#39;role\u0026#39; =\u0026gt; [\u0026#39;required\u0026#39;, Rule::in([\u0026#39;knight\u0026#39;, \u0026#39;thief\u0026#39;, \u0026#39;ghost\u0026#39;, \u0026#39;wizard\u0026#39;])], // and that they may get closures as parameters // (this will return the default error message) \u0026#39;items\u0026#39; =\u0026gt; [Rule::requiredIf(fn () =\u0026gt; $this-\u0026gt;role === \u0026#39;thief\u0026#39;), \u0026#39;array\u0026#39;], // or that a custom rule can be implemented as closure // this will return special error messages \u0026#39;spells\u0026#39; =\u0026gt; [\u0026#39;array\u0026#39;, function ($attribute, $value, $fail) { if ($this-\u0026gt;role !== \u0026#39;wizard\u0026#39;) { $fail(\u0026#39;Only wizards can cast spells\u0026#39;); } if (count($value) \u0026gt; 3) { $fail(\u0026#39;A wizard can only cast 3 spells\u0026#39;); } }], ]; } } Custom Rules #Often enough, these validations will contain some duplication. For example, in this RPG example, the game_id may only belong to a game which is not finished yet. This can be implemented as a custom rule. Laravel provides this using Invokable Rules, which contain a single method: __invoke. This method receives the attribute name, its value, and a callback that should be invoked on failure with the validation error message.\n\u0026lt;?php declare(strict_types=1); namespace App\\Http\\Rules; use Illuminate\\Contracts\\Validation\\InvokableRule; class UnfinishedGameRule implements InvokableRule { /** * @param string $attribute * @param mixed $value * @param \\Closure(string): \\Illuminate\\Translation\\PotentiallyTranslatedString $fail */ public function __invoke($attribute, $value, $fail): void { $game = Game::find($value); if ($game-\u0026gt;isFinished()) { $fail(\u0026#39;The game is already finished\u0026#39;); } } } This rule can be used in the FormRequest as follows:\n$request-\u0026gt;validate(['game_id' =\u0026gt; ['required', 'exists:games,id', new UnfinishedGameRule]]);\nRules offer some quite nice additions, like adding parameters to the Rule using its constructor, or implementing the DataAwareRule Interface which allows you to access the data of the request.\nValidations in Rules #In theory, this should be enough \u0026hellip; but when working with complex objects, it would be so nice to have a validation inside the Rule Object. Just implementing a new Validator inside of the Rule would be a nice solution, but leads to some problems:\nThe Validator will not return the correct error message, as it is not aware of the full attribute name (e.g. name instead of items.0.name) The nesting of the Error Bag will be messed up The original Validator will not be aware of the new rules, so it will not be able to access the data using $request-\u0026gt; safe(\u0026rsquo;name\u0026rsquo;) dependentRules will not be displayed using the correct attribute name (e.g. if one value must be greater than another, the error message will not be displayed correctly) To solve this, we can use the ValidatorAwareRule Interface, which allows us to inject the Validator into the Rule.\n\u0026lt;?php declare(strict_types=1); namespace App\\Http\\Rules; use Illuminate\\Contracts\\Validation\\InvokableRule; use Illuminate\\Contracts\\Validation\\ValidatorAwareRule; use Illuminate\\Support\\Facades\\Validator as ValidatorFacade; use Illuminate\\Validation\\Validator; class ItemRule implements InvokableRule, ValidatorAwareRule { protected Validator $validator; public function __invoke($attribute, $value, $fail): void { // 1. fix attribute name $attributeNames = collect($this-\u0026gt;rules($value))-\u0026gt;keys() -\u0026gt;mapWithKeys(fn (string $key) =\u0026gt; [$key =\u0026gt; $attribute . \u0026#39;.\u0026#39; . $key]) -\u0026gt;toArray(); $validator = ValidatorFacade::make($value, $this-\u0026gt;rules($value), $this-\u0026gt;messages()) -\u0026gt;setAttributeNames($attributeNames); // 2. The errors will be added to the parent validator. foreach ($validator-\u0026gt;errors()-\u0026gt;getMessages() as $key =\u0026gt; $message) { $this-\u0026gt;validator-\u0026gt;getMessageBag()-\u0026gt;add($attribute . \u0026#39;.\u0026#39; . $key, $message[0] ?? \u0026#39;Validation failed\u0026#39;); } } public function setValidator($validator): static { $this-\u0026gt;validator = $validator; return $this; } protected function rules(): array { return [ \u0026#39;name\u0026#39; =\u0026gt; [\u0026#39;required\u0026#39;, \u0026#39;string\u0026#39;, \u0026#39;min:2\u0026#39;, \u0026#39;max:100\u0026#39;], \u0026#39;description\u0026#39; =\u0026gt; [\u0026#39;nullable\u0026#39;, \u0026#39;string\u0026#39;, \u0026#39;min:2\u0026#39;, \u0026#39;max:100\u0026#39;], \u0026#39;price\u0026#39; =\u0026gt; [\u0026#39;required\u0026#39;, \u0026#39;numeric\u0026#39;, \u0026#39;min:0\u0026#39;, \u0026#39;max:1000\u0026#39;], \u0026#39;amount\u0026#39; =\u0026gt; [\u0026#39;required\u0026#39;, \u0026#39;integer\u0026#39;, \u0026#39;min:1\u0026#39;, \u0026#39;max:100\u0026#39;], ]; } protected function messages(): array { return []; } } Fixing the problems of Validations in Rules # Fixing the Attribute name Prefixing the attribute names will cause the error message to correctly display the path, e.g. \u0026ldquo;The items.0.name field is required\u0026rdquo; instead of \u0026ldquo;The name field is required\u0026rdquo;.\nBUT, this will not work if Rule again includes a nested Rule, as the attribute name will need to be prefixed again. Assuming that the array separator . is used, the contained attribute can be prefixed again. This code is not even close to a readable, good solution; if you have a better idea, please let me know.\n// The errors will be added to the parent validator. foreach ($validator-\u0026gt;errors()-\u0026gt;getMessages() as $key =\u0026gt; $message) { $newMessage = is_array($message) ? $message[0] : $message; // If the rule is nested, we need to replace the {key} placeholder with the parent key. if (str_contains((string) $newMessage, (string) $key) \u0026amp;\u0026amp; str_contains((string) $key, \u0026#39;.\u0026#39;)) { $newMessage = str_replace($key, $attribute . \u0026#39;.\u0026#39; . $key, (string) $newMessage); } $this-\u0026gt;validator-\u0026gt;getMessageBag()-\u0026gt;add($attribute . \u0026#39;.\u0026#39; . $key, $newMessage); } Fixing the Error Bag The errors will be added to the parent validator, so both the messages and the errors will not be empty. Mind that I only add the first error message.\nConveniently, the Validators will bubble their ErrorBags up, so this allows for recursive usage of nested Rules.\nFixing the Rules Because this is an array (I suppose), this works just fine without adding the rules to the original Validator. In other cases code like this might be helpful:\n// The rules will be added to the parent validator to access the attributes using e.g. $request-\u0026gt;safe(\u0026#39;key) $newRules = collect($validator-\u0026gt;getRules()) -\u0026gt;mapWithKeys(fn ($rules, $key) =\u0026gt; [$attribute . \u0026#39;.\u0026#39; . $key =\u0026gt; $rules]) -\u0026gt;toArray(); $this-\u0026gt;validator-\u0026gt;addRules($newRules); Fixing the Dependent Rule messages This will work with the fix of 1.\nRecursive Rules # New Feature Unlocked: For the validation of recursive data structures - this is one implementation idea. Adding a private property of the current nesting level to the Rule and incrementing it on each call of the Rule will enable the validation of the whole data without too much extra code, and enforce changing maximum nesting levels. Example for nesting:\npublic function rules(): array { return [ \u0026#39;name\u0026#39; =\u0026gt; [\u0026#39;required\u0026#39;, \u0026#39;string\u0026#39;, \u0026#39;min:2\u0026#39;, \u0026#39;max:100\u0026#39;], \u0026#39;description\u0026#39; =\u0026gt; [\u0026#39;nullable\u0026#39;, \u0026#39;string\u0026#39;, \u0026#39;min:2\u0026#39;, \u0026#39;max:100\u0026#39;], \u0026#39;price\u0026#39; =\u0026gt; [\u0026#39;required\u0026#39;, \u0026#39;numeric\u0026#39;, \u0026#39;min:0\u0026#39;, \u0026#39;max:1000\u0026#39;], \u0026#39;amount\u0026#39; =\u0026gt; [\u0026#39;required\u0026#39;, \u0026#39;integer\u0026#39;, \u0026#39;min:1\u0026#39;, \u0026#39;max:100\u0026#39;], \u0026#39;subItems\u0026#39; =\u0026gt; $this-\u0026gt;currentNestingLevel \u0026gt;= 3 ? [\u0026#39;prohibited\u0026#39;] : [\u0026#39;nullable\u0026#39;, \u0026#39;array\u0026#39;], \u0026#39;subItems.*\u0026#39; =\u0026gt; [\u0026#39;nullable\u0026#39;, new self($this-\u0026gt;currentNestingLevel + 1)], ]; } Conclusion #If such a complex validation is needed, it might be a good idea to use a custom Rule. If that custom Rule would benefit from implementing its own validation, this is possible with some workarounds. If recursive validation is needed, this can be achieved by enhancing the Rule with a private property for the nesting level.\nIf, on the other hand, the validation is not that complex, keep it simple.\nHappy Coding :)\nThat and more explained in the Laravel Docs.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"26 December 2022","permalink":"/posts/2022-12-rules-with-validators/","section":"Posts","summary":"Validations are great for ensuring that the data you receive is in the format you expect, while also handling a lot of edge cases (like ids that are not in the database).","title":"Laravel Validations"},{"content":"","date":null,"permalink":"/tags/validation/","section":"Tags","summary":"","title":"Validation"},{"content":" After debugging problems with the Serialisation of Classes, I learned I know way too little about Laravel Queues. So this article is me stepping down from the zenith of my personal Dunning–Kruger Effect curve and deconstructing the Laravel Queue To do this, I started my journey with a test - this is not for testing anything, it\u0026rsquo;s just a tool to lure the way through the magical forest of Laravel.\nnamespace Tests\\Feature; use App\\Models\\Game; use App\\Queue\\Events\\TestEvent; use Illuminate\\Support\\Facades\\Artisan; use Tests\\TestCase; class EventTest extends TestCase { public function testEvent() { /** @var Game $game */ $game = Game::first(); TestEvent::dispatch($game); Artisan::call(\u0026#39;queue:work --queue=game-queue\u0026#39;); $this-\u0026gt;assertTrue($game-\u0026gt;refresh()-\u0026gt;token === \u0026#39;Tested by Event\u0026#39;); } } Dispatching the Event #The Event that is dispatched in the first step is simple enough to be interesting inside the queue.\nuse App\\Models\\Game; use Illuminate\\Broadcasting\\InteractsWithSockets; use Illuminate\\Contracts\\Queue\\ShouldQueue; use Illuminate\\Foundation\\Events\\Dispatchable; use Illuminate\\Queue\\SerializesModels; class TestEvent implements ShouldQueue { use Dispatchable; use InteractsWithSockets; use SerializesModels; public function __construct(public Game $game) {} } Mind the Dispatchable trait, which will lead (using some magic helper function) to Illuminate\\Events\\Dispatcher::dispatch(). Ignoring Broadcasts here, the Dispatcher will determine the Listeners. To emphasize this - it is not the Event that is pushed to the Queue, it is the Listener.\nUnderrated Laravel Feature: Laravel has a Feature that enables the Connection of Events and Listeners without the usage ofa Service Provider. By just correctly Typehinting the Event in the Listener. Might be that it introduces more complexity for your deployment as you have to care more about Cache. 1\nuse App\\Queue\\Events\\TestEvent; use Illuminate\\Contracts\\Queue\\ShouldQueue; class TestListener implements ShouldQueue { public $connection = \u0026#39;database\u0026#39;; // can be in the env public $queue = \u0026#39;game-queue\u0026#39;; // was fun testing public function handle(TestEvent $event) { $event-\u0026gt;game-\u0026gt;update([\u0026#39;token\u0026#39; =\u0026gt; \u0026#39;Tested by Event\u0026#39;]); } } Each Listener determines if it is queueable (which means if it implements the ShouldQueue Interface). If not, the current container resolves the Listener and calls the handle function. If yes, the Listener is handed to the queueHandler. In this step, the Listener (and the Event it receives in its method parameters) are deconstructed. The Handle Method Arguments are mapped into an Array including ALL its attributes (including private or protected ones). If the Event contains complex properties, this might cause problems. An Event should be as simple as possible.\n$arguments = array_map(function ($a) { return is_object($a) ? clone $a : $a; }, func_get_args()) After mapping the arguments the Listener will receive, the Listener is packed in a new CallQueuedListener($class, $method, $arguments). This object is also filled with the Queue Name and the Connection, both usually set in the environment, but can be overwritten in the Listener.\nPushing and serializing the Listener #Then, corresponding again to the connection, the Queue is called via Illuminate/Queue/DatabaseQueue::push. The Queue is responsible for defining the Payload. For this the Job (which holds the Listener) is Serialized serialize(clone $job); 2 and then pushed to the Queue.\nThe goal of Serialization is to convert a complex data structure into a storable representation of a value (in this case a JSON String). This should not be used for storing objects in the Database in a normal case, but in this case, it\u0026rsquo;s used to store the Listener in some kind of queue, as well as its current state. The Constructor is not serialized, so dependency Injection is still possible in the Listener.\nSmall loop back the Event and the SerializesModels Trait. This Trait contains implements a __serialize() function, which overwrites the normal serialization, so the object stored on the queue is way smaller and only contains the identifier, a list of eager loaded relations and changed attributes.\nWarnings regarding Serialization: When serialize() serializes objects, the leading backslash is not included in the class name of namespaced classes for maximum compatibility. Also, not everything is serializable, one limit are Closures. With all that the payload looks something like:\n{ \u0026#34;uuid\u0026#34;: \u0026#34;66b9777e-221d-4c8e-9b4e-8870d7d6aec2\u0026#34;, \u0026#34;displayName\u0026#34;: \u0026#34;App\\\\Queue\\\\Listeners\\\\TestListener\u0026#34;, \u0026#34;job\u0026#34;: \u0026#34;Illuminate\\\\Queue\\\\CallQueuedHandler@call\u0026#34;, \u0026#34;maxTries\u0026#34;: null, \u0026#34;maxExceptions\u0026#34;: null, \u0026#34;failOnTimeout\u0026#34;: false, \u0026#34;backoff\u0026#34;: null, \u0026#34;timeout\u0026#34;: null, \u0026#34;retryUntil\u0026#34;: null, \u0026#34;data\u0026#34;: { \u0026#34;commandName\u0026#34;: \u0026#34;Illuminate\\\\Events\\\\CallQueuedListener\u0026#34;, \u0026#34;command\u0026#34;: { \u0026#34;class\u0026#34;: \u0026#34;App\\\\Queue\\\\Listeners\\\\TestListener\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;handle\u0026#34;, \u0026#34;data\u0026#34;: [ { \u0026#34;arePublicsGettingSerialized\u0026#34;: true, \u0026#34;game\u0026#34;: { \u0026#34;class\u0026#34;: \u0026#34;App\\\\Models\\\\Game\u0026#34;, \u0026#34;id\u0026#34;: 1, \u0026#34;relations\u0026#34;: {} }, \u0026#34;socket\u0026#34;: null } ], \u0026#34;tries\u0026#34;: null, \u0026#34;maxExceptions\u0026#34;: null, \u0026#34;backoff\u0026#34;: null, \u0026#34;retryUntil\u0026#34;: null, \u0026#34;timeout\u0026#34;: null, \u0026#34;shouldBeEncrypted\u0026#34;: false, \u0026#34;job\u0026#34;: null, \u0026#34;connection\u0026#34;: null, \u0026#34;queue\u0026#34;: null, \u0026#34;chainConnection\u0026#34;: null, \u0026#34;chainQueue\u0026#34;: null, \u0026#34;chainCatchCallbacks\u0026#34;: null, \u0026#34;delay\u0026#34;: null, \u0026#34;afterCommit\u0026#34;: null, \u0026#34;middleware\u0026#34;: [], \u0026#34;chained\u0026#34;: [] } } } Notes on Method Locations:\nWhile most of the above happen inside the specific Queue (like DatabaseQueue), all Queues I found are using the createPayload() inside the Illuminate\\Queue\\Queue. I assume this is to make sure the Payload looks the same for every Driver and can be read by every worker. But here is one weakness of the Laravel Queue:\nIn complex systems it might be useful to use Events to communicate between different Services throughout the System, writing and listening to the same queue. Implementing something like that in Laravel would require writing a new Queue, maybe not using the createPayload() function, which sounds like a slippery slope; but if you went it down, I would be curious to hear about it.\nNow, what\u0026rsquo;s left is building the Database entry. After this the container might get deconstructed, the PHP thread changes, everything after this step happens at a different time - maybe on a different server! What feels like implementing an \u0026ldquo;empty\u0026rdquo; Interface like ShouldQueue without a great impact on local Development with QUEUE_CONNECTION=sync hides the code and context switches happening on production.\nprotected function buildDatabaseRecord($queue, $payload, $availableAt, $attempts = 0) { return [ \u0026#39;queue\u0026#39; =\u0026gt; $queue, \u0026#39;attempts\u0026#39; =\u0026gt; $attempts, \u0026#39;reserved_at\u0026#39; =\u0026gt; null, \u0026#39;available_at\u0026#39; =\u0026gt; $availableAt, \u0026#39;created_at\u0026#39; =\u0026gt; $this-\u0026gt;currentTime(), \u0026#39;payload\u0026#39; =\u0026gt; $payload, ]; } Working the Queue #Working the queue is triggered by a Command, the Illuminate\\Queue\\Console\\WorkCommand::handle(). This command triggers a worker to run as daemon, which means it uses a while(true) loop to run until its break conditions (e.g. Maintenance Mode) are triggered 3. To emphasize this: The Worker is not a daemon in the sense of a Linux Daemon, it\u0026rsquo;s php code running inside a Laravel application. Which for me raised the question if all Jobs processed by the Worker are processed in the same context / Container. Short answer is Yes, or as it\u0026rsquo;s stated in the Laravel Docs:\nRemember, queue workers are long-lived processes and store the booted application state in memory. As a result, they will not notice changes in your code base after they have been started. 4\nNot so short answer is: in production, no. A line of code I even put in my deployment script includes a Supervisor which will restart the worker every hour or after a certain number of jobs 5. Again emphasizing, because I did not expect it to work like this: Laravel uses a non Laravel Superviser task to control a Laravel Container which would otherwise just keep on running on the server, which is working all the jobs in the same context in its queue with no build in capability of sharing that queue with other applications. I mean it works.\nIn this loop, it will call Illuminate/Queue/DatabaseQueue::pop to fetch the next Job and unpack it into a Job, in this case, an Illuminate/Queue/Jobs/DatabaseJob. The Worker will raise an Event before the Job starts and after the Job finished (or failed). Finally, the Jobs fire() method can be called, which instantiates the Listener and calls the specified method with the Event as a parameter.\nConclusion #I wrote this article to understand the Laravel Queue better, what parts can be dangerous and what hooks I can use if I need a different behavior than the Laravel default.\nHappy Coding :)\nLaravel provides some information about the queue.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSerialise function, how to overload it, and more. As so often, the best comments are better than the manual.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDeep Dive into Laravel Work Command\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLaravel Docs to explain how the worker is a long-lived process\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSupervisor is a process control system that allows you to monitor and control a worker\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"11 December 2022","permalink":"/posts/2022-12-queues/","section":"Posts","summary":"After debugging problems with the Serialisation of Classes, I learned I know way too little about Laravel Queues.","title":"The Laravel Queue"},{"content":" As a developer, most of the meetings I join I either want to talk about code, or I am asking myself why I joined the meeting, and if I would not be more productive writing code. Retrospectives are an exception. I love retrospectives. I enjoy the feeling of improvement after a retro, I like the open communication of retros, and I like the feeling of being heard. Retros by Scrum Definition #A Retrospective is a meeting that is focused around improving the processes in and around a team. It often happens after the sprint and addresses stumble stones that happened during the sprint. It\u0026rsquo;s neither about blaming people nor about whining, it\u0026rsquo;s about improving productivity, effectiveness, and developer happiness. In the Retrospectives I attended, common discussion topics include how much can business interrupt in the sprint; how should communication happen between teams, how is the team defining definition of done / ready / production ready; or what meetings should be required for developers or maybe need time changes 1.\nDuring the Sprint Retrospective, the team discusses: What went well in the Sprint What could be improved What will we commit improving in the next Sprint Little dangers of Retros #Retrospectives come with some dangers. They are often all-hand-meetings, which means if they become useless often two working hours per developer and scrum master are wasted. The developer happiness wasted by frustrating meetings is what bugs me personally, but for some managers, it is easier to argue with the cost of a meeting. The hours of meeting, times the number of people, times the hourly rate of everybody quickly ends up in a number big enough that even the cost-focused managers value the time of team members.\nTo keep the Retrospectives useful, they need to be goal-oriented, honest, and what I would call in german \u0026ldquo;kurzweilig\u0026rdquo; - which translates to feeling quick and amusing. More agile definition trained people have written posts on how important it is to make it a safe space for the team to talk about what is not working; and how it is important to have measurable changes that have an impact on the team. What I was missing in the retrospectives I attended was a bit of the fun part.\nRetrospectives Gamification #I went to some retrospectives where the team was asked to display their mood using a weather frog in the best case, or to write down their problems on sticky notes and then put them on the same three colored miro rectangles every sprint in the worst case. It\u0026rsquo;s not bad\u0026hellip; it\u0026rsquo;s just boring.\nFor my current team, I started to make the retrospectives a bit more fun. I started with different themes, and people enjoyed it. People started to ask how I created them, what my references where, and how I would come up with the ideas - so this post will be both an idea for interested, a guide for creators, and a collection of themes for those who just want ready to use themes (never mind that; explained in the last paragraph).\nUsing themes for asking different questions #Start, Stop, Keep #The most commonly described Retro Questions are What should we start to do?, What should we stop doing?, What should we keep doing?. Those questions have their reasons and fulfill what a Retrospective wants to achieve. However, asking every time the same questions in my experience leads to the same answers. Although Scrum Masters would appreciate it, most Dev Teams do not collect various points to improve throughout the sprint, and then discuss them in the retro. Instead, they discuss what comes to their mind the moment they are asked - This is not blaming, it\u0026rsquo;s mostly self-observation.\nThe following Questions are more or less rephrasing these base questions of Retrospectives. Asking in different ways can lead to new answers and also can give each Retro a theme by itself, a team that is happy in the current setting might benefit more from talking about what tools or practices could be added, while a fresh team might focus on well-being.\nAll upcoming ideas are focused on the idea of sharing a view (live or virtual) and placing post-it like notes on a board.\nFinding good and bad practices #When evaluating practices it can be helpful to guide the team using one (or multiple) axes. Depending on the Situation just asking for good or bad practices can be enough, but e.g. after a troubled sprint it might be helpful to ask for specific practices for prevention or future firefighting; if the Team is looking for new technology a cloud or tree can be used to group discussions in different branches of topics; and if working with existing metrics those metrics can be used to place member opinions; during special occasions just rephrasing the question can be fun - like asking for the best tricks or treats in Halloween themed retro.\nCommunicating Doubts #Although this might be included in the bad practices, often enough precisely asking for problems and doubts can reveal more problems and encourage a discussion in the team. To support the discussion in the Retrospective, different axes and designs can again add value compared to the (still valid and useful) word cloud. Some examples are adding Priorisation to encourage the team to not only add topics that need improvements but also to rank them on their urgency; if the topics that need change are already known, a heatmap can be visualised what the important pain points are; on the other hand to discover new improvement points a categorisation can refine and increase the results; last but not least sometimes negating the question can lead to a different point of view and again reveal unknown concerns.\nFinding Vision and Celebrating Success #Celebrations are often left out, but I enjoy the idea of celebrating the little learning we found to communicate them and to encourage going deep to understand the framework, the domain, or the customer better. For developers who don\u0026rsquo;t enjoy bragging in the daily about what they learned, dedicated badges can be a nice starting point. (I would award code, features, ideas, or situations instead of people). Regarding Vision and goals, of course the word cloud is again a valid idea (the theme example of dishes as above can be reused - \u0026ldquo;what spices are missing in our success / code recipe?\u0026rdquo;). But it\u0026rsquo;s again more effective to also rate the improvement ideas by the time frame in which an idea adds value to the company / team / codebase. If the main goal is to first come up with any ideas, a Venn Diagram can be helpful to identify differences between the team goals (like a well tested code base) and the business goals (like new features now).\nMood Check #Last but not least, a mood check can be helpful to identify the general feeling of the team and can be just fun. Any spectrum of \u0026ldquo;feeling alive?\u0026rdquo; can give a quick overview of the individual mood; if sticking your note in the same place every time became a habit, it can be helpful to move the \u0026ldquo;feeling good\u0026rdquo; spot on an axis to the center. Also, a fun exercise is to give a theme and ask for one word to describe the last sprint. Similar to the other questions, of course categorisation can again help to discover new problems in the team by enforcing questioning some practices in the team.\nSpecial Retros (updated 29.12.2023) #From time to time, a special retro can provide an overview of the team\u0026rsquo;s long-term state, can be used to celebrate very big milestones, or fill retros which will presumably not be very productive.\nTimeline Retros #Perfect for pre new year retrospectives, or for retrospectives after finishing a great milestone.\nFirst Step - Reconstruct the timeline: A timeline over a selected time frame (e.g. the last half year) is provided. Additionally, a set of categories (new Team member started, achievement unlocked, new technology introduced, \u0026hellip;) or some timeline distinctions (team events, company events, \u0026hellip;) may be provided as help. In our team, it was helpful to do this step as discussion instead of individual work, as already in this step the team discovered that the team does not remember achievements and want to celebrate them more.\nI already find this step very valuable, and the next step depends on the team capabilities to communicate their feelings. Not all teams are comfortable sharing their feelings, but if they are, the next step can provide nice insides.\nSecond Step - Match the teams feelings: The team is asked to place their feelings on the timeline. This can be used to discuss what events changed the team\u0026rsquo;s mood, and what events can maybe celebrated or discussed in future.\nCollection of Themes #The idea of this blog was to publish my themes. I made themes like:\nPokemon: What was your hardest battle? On a scale of \u0026ldquo;Developer fainted\u0026rdquo; to \u0026ldquo;Developer had a critical hit\u0026rdquo; - how was the sprint? \u0026hellip; Don\u0026rsquo;t Starve (the video game): What is your sanity level after the sprint? What monsters scared you the most? \u0026hellip; Pen and Paper: What was your hardest dungeon? What was your best item? \u0026hellip; Beer pong: What was your best trickshot? \u0026hellip; \u0026hellip; (an more, this list will not be updated) 2 BUT, I don\u0026rsquo;t feel comfortable publishing them because I am scared of copyright problems. I respect the work of the different artist, I am sure if I would ask them I could use the pictures, but honestly, I am too lazy for that as well. So take this advice:\nBe creative, use cool themes, make your developers smile at your themes - everything is allowed. Steal the questions and setups from this and other blogs, and color it with whatever your devs enjoy; when in doubt, add a unicorn 🦄.\nHappy Coding :)\nStolen from Scrum.org\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFor inspiration use this Set of Themes with questions and online tools\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"10 October 2022","permalink":"/posts/2022-09-sprint-retro/","section":"Posts","summary":"As a developer, most of the meetings I join I either want to talk about code, or I am asking myself why I joined the meeting, and if I would not be more productive writing code.","title":"Improving Retros from a Devs Perspective"},{"content":"","date":null,"permalink":"/tags/developer-life/","section":"Tags","summary":"","title":"Developer Life"},{"content":"","date":null,"permalink":"/tags/ethical-development/","section":"Tags","summary":"","title":"Ethical Development"},{"content":" Ethical behaviour helps a social group to flourish, and strives to develop the best possible version. Formulating it this way maybe describes why even the most rational minds in development should hold a second to think about the code they are designing, implementing, or requesting. This post is focused on one question: From an ethical point of view - Is your code good? Why ethical values matter in Development? #The trend towards ethical development is present in many ways. Social Networks may implement algorithms to reinforce hateful but wide spreading content; smart home gadgets may contain sensors and microphones and therefore provide more features and more engagement for exploiting; Governmental software is developed around the small border between functionality and respect for their user privacy. Not in every company or context does society benefit from caring about ethical issues; bitching about the cookie policy of a start-up might not make the world a better place; but many developers, product owners, managers do not realise the ethical impacts of their decisions.\nWhere to learn: IEEE # Many clever people are thinking about the topic, my first touching point was IEEE, and it nudged me to wander down in the IEEE forest of interesting thoughts of engaged people all around the topic of ethics in technology. The fact that I did that, does not mean it\u0026rsquo;s the only source of truth, neither that it is best, nor that you should do the same - It was/is my path, and I want to share my experience with that, and maybe inspire you to click on one of the links at stroll yourself through the forest of information about ethics in IT. Contemplating ethical stumbling stones # IEEE’s CertifAIEd program objective is to enable, enhance and reinforce trust through AI Ethics specifications, training, criteria, and certification. It stems from the rationale that an entity benefits from an independent ethical evaluation and certification of its AIS. 1\nAlthough I have worked with AI, in my day-to-day business it\u0026rsquo;s a tool I use, not the focus of my development business. Anyway, the information IEEE offered was enlightening beyond the topic of machine learning. Being more aware of the different areas in which I as a developer can encounter ethical issues while designing, implementing, or maintaining a feature is a great help in avoiding ethical issues even before the first function call is written.\nThe following sections are the information I remember from the training. \u0026ldquo;Remember\u0026rdquo; like a not-complete list of hints, metaphors, information, etc, that I found interesting enough to keep in mind. The CertifAIEd Program has (at time of this post) 4 areas on interest: Transparency, Accountability, Algorithmic Bias, and Ethical Privacy.\nTransparency #Metaphor: In case of questions about a past flight (e.g. in case of a successful emergency landing, or a crash) there are two black boxes on an airplane. The first one, the flight data recorder (FDR) records multiple technical parameters about the state of the airplane and its surrounding. The second, the cockpit voice recorder (CVR) records the conversation of the pilots in the cockpit. This metaphor can guide the two aspects of transparency.\nThe first is technical transparency. What data is recorded, how does it flow through the systems, and which decisions are made by inside code? Especially in the context of anything that is labeled AI - to what degree does the developer understand their algorithm? Is it clear to the developer how the system will be used by the end user? Who are the users, is authentication tracked, activities logged, and errors handled? Mentioning the user, does the end user know how the system works, are they aware of any automated systems that make decisions in the background, do they understand or at least suspect how the algorithm decided on the displayed content, do they realise how the data is evaluated, stored, or sold?\nSecondly, the cockpit voice recorder: How did management make their decisions? Which business assumptions were made, and how have they been communicated to development or sales? Does the company have an ethical set of values, and do structures exist to enforce these? Those questions are not always easy, sometimes impossible to publish. But if possible a company may benefit from providing information about their values.\nAccountability #Rubber stamps were used since the 18th century to mark documents as \u0026ldquo;seen and approved\u0026rdquo; by a given person following some bureaucratic process. From that origin, the metaphor of rubber-stamping describes the tendency to uncritically approve a given statement.\nThis tendency is one red flag when looking for accountability in a company. Enough bureaucracy can bury any liability - some person approved this, some person for sure took responsibility for this; or vice versa the tendency to approve something uncritically as part of the process without questioning them to be approved.\nBeing accountable does not end with a signature below a document to mark it as seen. An accountable person should be able to display enough understanding of the subsystem in question to answer questions reliably. There is no black box argument excuse to this - even if the subsystem in question is a black box for the accountable, answerability is not optional. Additionally, this is not restricted to technical subsystems, but includes decisions and policies.\nMy two cents as a developer on this: As a developer, I often find myself in the position in which a manager might be accountable for the feature I am asked to implement, while at the same time I might be capable of foreseeing ethical issues he can\u0026rsquo;t in context of the requested way of implementation. This includes unethical features, like tracking sensible data, as well as unethical ways of implementation, like keeping deleted user data in the backup files. I find myself responsible for at least questioning such requests, double-checking if the ethical problems have been accounted for, and sometimes refusing to fulfil the request. Not only, but especially as a developer, my decisions can have an impact on feature development, my workforce is one of the most powerful resources I have to influence the future. Ethical value standards should come top to bottom, but I encourage everybody to not underestimate the power of a single person questioning management requests.\nAlgorithmic Bias #Computers are rational and free of human bias. That\u0026rsquo;s what a lot of people, developers often up front, assume. People tend to forget that every line of code is written by a human, prone to human bias. The view of computers as rational, correctly calculating machines is especially dangerous if their algorithms contain repeatable errors, making decisions about human beings resulting in unfair outcomes for one subgroup of users - all covered in the disguise of rational calculations 2.\nThe classical examples for these situations are Human Resources applicant classification algorithms fed with the biased data of preferably male employees which will transfer these biases into the hiring processes; or an image recognition algorithm that will not be able to identify people of colour with the same accuracy if it was fed the predominantly white images. Of course, examples that are worth mentioning, and far from being solved; but examples a lot of developers already have in mind. Still, there are many ways a product or service may show bias in situations in which developers are less aware of possible problems.\nOne of these situations is neglected product context. A product or service may work without bias in on situation or target group, but cause unfair outcomes when used under different circumstances. But bias can be minimal and sublet, like online forms which do assume that a family name has a minimum length or that there is exactly one (or exactly two) family names, forms which assume a postal code is numeric, forms which assume certain letters do not exist in names or email addresses - in general, assumptions developers made often without realising that there are edge-cases in which their desiccation impedes the usage of their web site to some users.\nEthical Privacy #Have you accepted the cookies for this page? No, you did not. There are no cookies, no trackers, no information I collect about you, dear reader. The main reason for this is not that I am not interested in who is visiting this page, instead, I avoid the fuss of respecting your data ethically and legally. While this blog does not, a lot of IT business models are based on the collection, classification, and interpretation of user data. This is nothing bad, it just is the usage of the technology we have often enough with good intentions to offer services people are consuming.\nCollected data becomes an object of ethical considerations if it is misused, its usage is mis-communicated, or if the data is available to third parties due to the carelessness of the company.\nRespecting the person and their digital representation comes with a separation of the data that a company may be able to collect, data a company needs to collect to provide a service, and data that might be useful for the company but is not part of its current daily business. This leads to the question if the company has communicated which data is collected for which reason. Thanks to over-complicated laws, Terms and Conditions offer a length which feels similar to the modern infinity scroll of Instagram. What part of the Terms and Conditions do you read? Do you scroll through the settings of any installed application to switch out any data sharing options? Do you share the crash report if a software on your computer experienced an unexpected event?\nA company may offer the user options to decide which data they want to share, and a company may decide on how clear, understandable, and accessible these options are. Same holds for information on how the data is used. It\u0026rsquo;s the company\u0026rsquo;s decision how to present this information to the user.\nSo what now? #Takeaway so far: at least I was surprised how often I touch ethical problems without thinking about them when writing those colourful letters on dark background. But what to do with that feeling of newfound awareness? The first thing that changed for me is positively or negatively recognize when software, websites, or IT companies cared about ethical values. Secondly, I am in a position in which I might be able to change a feature of a software product during its design and development. I am not in the position to certify or consult a company - pointing to the accountability section - but I do hold my ground to call out ethical concerns as I encounter them in new features. This is no framework, nor guidelines but barely personal recommendations.\nIntroduce the new stakeholder #In every Feature discussion, there are more stakeholders than visible at first glance. There is the capitalistic stakeholder asking for short-term revenue, the C-Level asking for long time revenue, the marketing people who want the feature to fit on an online ad, the motivated tech person who is looking forward to trying out that new technology, the concerned senior dev who wants their code base clean and tidy. One physical person may function as multiple stakeholders. With the ethical topics in mind, having one person in such meetings who will play the role of the concerned activist, or the role of a not digital native who has a hard time understanding how their data will be used, or the role of a critical thinker who wants to know how the company makes a decision, or the role of a person of a minority group. A feature is always viewed from a different point of view, take your time to add additional views to be aware of ethical problems 3.\nKnow your values #A finance company might value privacy, a company that offers CO2 tracking might value sustainability. Not every company has the same values, and objectivity of values is a discussion of its own. So take some time to talk about the values of your company. Talk about the ideas and values of the management and C-Level, about the deal-breaker for developers, and the ethical standards that you agree upon for your business. Business values do not need to be the same as private values, there are valid reasons why you as person does not agree with the values of a social network, but as a ( self-chosen) employee, your values should at least align with the company values.\nTalk about and document the company values #Make it a habit to talk about the values, to document the problems you found in a feature. Make a comment above a code you wrote for an ethical reason or about the danger you expect if that line might be changed. Encourage the discussion and share blog posts that point out wrong assumptions in programming or UX 4. Provide a space for such discussions and maybe even support that people educate themselves on such topics.\nAccept the possibility to stop a feature if it does not fit your values #All of the above does not hold value if you are not able to stop the development of a feature if you can not align it with the decided company values. Even if some CEO thinks it\u0026rsquo;s a great benefit to misuse user data, or accounting would go for profit optimisation by selling user data, or some developer would like to keep that cool backdoor they put in the code for whatever reason.\nIf you want to check your product or service for ethical problems, but you are not convinced to change something if you find some; rethink your incentives, because they might be more marketing focused than actually ethical doubts.\nConclusion #This post is aims to inspire, to sensibilize for stumbling stones that might have been overlooked easily. I want to encourage the reader to think about values when coding. Because even though it feels like a developer is focused on the technical problems they solve daily, there are social and ethical problems they should not ignore.\nPlease feel free to, if you feel curious, have a look the IEEE Standards. The people behind the standards are motivated, super open for critique, and offer a great set of courses I can only recommend.\nHappy and respectful coding :)\nCheck our the CertifAIEd programm by IEEE\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAlgorithm Watch has a great Article with multiple case studies on this topic, and also offers a checklist to reduce the biases in software.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEthically Aligned Design, including the book more information about this process here\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFor your next discussion about validation rules on forms read Falsehoods Programmers Believe About Names\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"31 August 2022","permalink":"/posts/2022-08-etchical-development/","section":"Posts","summary":"Ethical behaviour helps a social group to flourish, and strives to develop the best possible version.","title":"Ethical Development"},{"content":" Simple REST APIs are nice. But once a Controller needs to perform more than just the basic update, create, and index methods; Once a Controller maybe ought to handle multiple little tasks, tasks that may be used in various places in the code base, there is a need for a Software Pattern. Something that fulfills the desire to have one class or method do only one thing - Single Responsibility. This Post compares Repositories, Services, Actions, Jobs, and Events - not to find the best for all use cases, but to formulate some words on the question when the different patterns offer advantages over the others. Writing a Controller that adds a new user as player to an existing game #Taking my favorite example, Round Robin - a little round-based gaming platform to register and play games with friends. A new user just registered and already has a game token, so they can just join an existing game. This means, within the request to (1) create that user, also a (2) player needs to be created, and (3) that player must be configured e.g. become a member of a color-coded team.\nOf course there are reasons to do some things using precisely one pattern (like sending an email using an event, or updating using a repository). This blog is a collection to compare some patterns that want to move code from the controller to different files. The example is used for visualisation, not because it is so hard to decide which pattenr to use in this case Just a Controller #For simplicity, let\u0026rsquo;s assume all security validations have been made in the request by magic. The reason for this post is that multiple things are ought to happen in this controller, some of those things are also happening in different parts of the application, and I need to find a pattern to organize my code.\nSo using nothing but the Model View Controller pattern, I end up with this code:\nclass UserController { public function register(Request $request) { // step 1: create the user $user = User::create($request-\u0026gt;data()); Auth::login($user, true); if (! $request-\u0026gt;input(\u0026#39;token\u0026#39;)) { return return view(\u0026#39;game.index\u0026#39;); } // step 2: Create the player $game = Game::query() -\u0026gt;where(\u0026#39;token\u0026#39;, $request-\u0026gt;input(\u0026#39;token\u0026#39;)) -\u0026gt;firstOrFail(); $player = $game-\u0026gt;players()-\u0026gt;create([ \u0026#39;uuid\u0026#39; =\u0026gt; Str::uuid(), \u0026#39;user_id\u0026#39; =\u0026gt; Auth::id(), ]); // step 3: Prepare the Player for the game $redPlayers = $game-\u0026gt;players()-\u0026gt;where(\u0026#39;color\u0026#39;, \u0026#39;red\u0026#39;)-\u0026gt;count(); $bluePlayers = $game-\u0026gt;players()-\u0026gt;where(\u0026#39;color\u0026#39;, \u0026#39;blue\u0026#39;)-\u0026gt;count(); $player-\u0026gt;color = $redPlayers \u0026gt; $bluePlayers ? \u0026#39;blue\u0026#39; : \u0026#39;red;\u0026#39; $player-\u0026gt;save(); return view(\u0026#39;GamePage\u0026#39;, [\u0026#39;game\u0026#39; =\u0026gt; $game]); } } Not very reusable\u0026hellip; so let\u0026rsquo;s have a look at the Laravel Docs and common Patterns to improve the situation.\nRepository Pattern #If there was a layer between the Database and the Controller, something that handles the creation of models - wouldn\u0026rsquo;t that be nice? Using Dependency Injection of Laravel, you could follow such a pattern:\nclass UserController { public function register(Request $request, UserRepository $userRepository, PlayerRepository $playerRepository) { // step 1: create the user $user = $userRepository-\u0026gt;createUser($request-\u0026gt;data()); if (! $request-\u0026gt;input(\u0026#39;token\u0026#39;)) { return return view(\u0026#39;game.index\u0026#39;); } // step 2: Create the player $player = $playerRepository-\u0026gt;createPlayer([\u0026#39;token\u0026#39; =\u0026gt; $request-\u0026gt;input(\u0026#39;token\u0026#39;)]); // step 3: Prepare the Player for the game $redPlayers = $game-\u0026gt;players()-\u0026gt;where(\u0026#39;color\u0026#39;, \u0026#39;red\u0026#39;)-\u0026gt;count(); $bluePlayers = $game-\u0026gt;players()-\u0026gt;where(\u0026#39;color\u0026#39;, \u0026#39;blue\u0026#39;)-\u0026gt;count(); $player-\u0026gt;color = $redPlayers \u0026gt; $bluePlayers ? \u0026#39;blue\u0026#39; : \u0026#39;red;\u0026#39; $player-\u0026gt;save(); return view(\u0026#39;GamePage\u0026#39;, [\u0026#39;game\u0026#39; =\u0026gt; $player-\u0026gt;game]); } } The great thing about a Repository is, that it is the single point in the code base, that creates, updates, or queries Models. There are a lot of use cases in which this can be super helpful - e.g. if you want to validate your Models before updating or authorizing queries. The separation of the writing and reading part of a Repository can be achieved by using 1. The Repository does a great deal for separation of concerns and single responsibility ( your software pattern bingo game should have caused one win by now).\nBut it can\u0026rsquo;t solve all problems, as you can see the third step is not the job of the Repository. Arguably it could be implemented there, as one can argue that the correct color of a player is somewhat a validation topic, but treating a Repository like that will make it the \u0026ldquo;core service\u0026rdquo; of the application soon. It is not the job of the Repository to care about everything that occurs with the creation of a Model, it just cares about the creation of the Model.\nService Pattern #If there was a place to just hold all the methods that might be used multiple times - wouldn\u0026rsquo;t that be nice? Mind that this is not the Service Provider that Laravel mentions, at least I could not come up with a reason why a Service like that would need to be registered or requires to be a singleton.\nclass UserController { public function register(Request $request, UserService $userService, PlayerService $playerService) { // step 1: create the user $user = $userService-\u0026gt;register($request-\u0026gt;data()); if (! $request-\u0026gt;input(\u0026#39;token\u0026#39;)) { return return view(\u0026#39;game.index\u0026#39;); } // step 2: Create the player $player = $playerService-\u0026gt;createPlayer($request-\u0026gt;input(\u0026#39;token\u0026#39;)); // step 3: Prepare the Player for the game $player = $playerService-\u0026gt;initatePlayer(); return view(\u0026#39;GamePage\u0026#39;, [\u0026#39;game\u0026#39; =\u0026gt; $player-\u0026gt;game]); } } Feel the freedom of doing more than just creating and updating, listen to the single Responsibility Pattern softly crying in the corner, and watch your services grow to reach the 4-digit line numbers! Services are a great way to encapsulate logic around one component. In my experience, it is just hard to set boundaries, and in a larger application (or one that can have the potential to grow) I would not use this pattern and go for something that gives the next developer who might continue on my code a stricter line on where to find and add code.\nOne additional note: there is no limit on patterns, Services and Repositories might work together quite well and 2.\nAction Pattern #If there was just one class, that does exactly the one thing, and may be reused in Controllers, Jobs, Commands, whatever - wouldn\u0026rsquo;t that be nice?\nclass UserController { public function register( Request $request, UserCreateAction $userCreateAction, PlayerCreateAction $playerCreateAction, PlayerInitialisationAction $playerInitialisationAction, ) { // step 1: create the user $userCreateAction-\u0026gt;execute($request-\u0026gt;data()); if (! $request-\u0026gt;input(\u0026#39;token\u0026#39;)) { return return view(\u0026#39;game.index\u0026#39;); } // step 2: Create the player $playerCreateAction-\u0026gt;execute(token: $request-\u0026gt;input(\u0026#39;token\u0026#39;)); // step 3: Prepare the Player for the game $playerInitialisationAction-\u0026gt;execute(); // imagine there is a custom Auth Facade extending the Auth Facade ... return view(\u0026#39;GamePage\u0026#39;, [\u0026#39;game\u0026#39; =\u0026gt; Auth::player()-\u0026gt;game]); } } One Action, one class per action, one concern per class - everything is separated and clean. Using this pattern can lead to very clean actions, that can be inside of Controllers as well as Jobs as well as Nova Actions. Every bit of the Business Logic broken down into simple pieces. And the single Actions are just so easy to test - some unit tests per Action will increase the Test coverage fast and if all the little gears are working half the bugs are avoided. And then you can just avoid using Events at all, because using the right packages will enable your actions to run on queue 3.\nThis pattern is the reason for this post. I am working with this pattern for some months now and have to admit, it is neat. Combined with some naming convention (spare some fuzz, suffix your actions with \u0026lsquo;Action\u0026rsquo; from the very beginning\u0026hellip; and while you are at it, just suffix everything that is not a Model).\nI still have my concerns: While the Project grows, so first and for most your /actions folder grows, there is one feature of Actions that I see as the biggest pro and con. Compared to Events, which are created, put on queue, and in some ballet of Laravel Magic listened to at some point; Actions stay controllable. The Controller, or what ever point of execution is calling the Actions like a conductor is flicking their want to initiate a calculated, controlled set of actions. In a lot of use cases, this is a great tool of control - in others the freedom of hooking in between and after any of those actions can be integrating, sometimes even necessary. Following the Action Pattern, such add-a-hook changes can be frustrating to implement as each conductor has to follow the new life cycle, instead of having one place in which such a life cycle event may be added.\nUsing Jobs for Action Pattern #This little question bugged me after discussing the topic with some colleagues. Why use Actions, if they could be Jobs? Why not use the Framework that we Artisans admire, and just take the Jobs, may or may not make it Dispatchable or / and Queueable and just use those as queueable actions without any package dependency? All the special features of Jobs, like rerunning on error, or unique running could come in super handy.\nIt is like taking a sledgehammer to crack a nut, but starting a Job should not be that much of a time spent, especially if it is not Queueable anyway. One drawback for sure is the missing option to return something from your action, which I would argue is a bit of code smell anyway.\nHonest answer to this section: No idea, would love to try, if you have a comment on that - please email me, I would appreciate the discussion!\nEvent - Listener Pattern #If we could just state what happened in the Controller, everything that wants to react to the thing that happened can do so - wouldn\u0026rsquo;t that be nice?\nclass UserController { public function register(Request $request) { // step 1: create the user $user = User::create($request-\u0026gt;data()); Auth::login($user, true); UserCreated::dispatch($user); return view(\u0026#39;GamePage\u0026#39;, [\u0026#39;game\u0026#39; =\u0026gt; Auth::player()-\u0026gt;game]); } } // In the Event Service Provider protected $listen = [ UserCreated::class =\u0026gt; [ // step 2: Create the player CreatePlayerIfTokenIsPresent::class, ], PlayerCreated::class =\u0026gt; [ // step 3: Prepare the Player for the game InitiatePlayer::class, ], ]; So little code\u0026hellip; so clean, almost no newbie will know where to find everything, but a Laravel affine Developer might look at the Service Provider (that might be one of many Service Providers, e.g. one for each Domain), and see how Data might flow through the Application in a barely controllable way once the event has been dispatched.\nThis is the pattern of choice if your tasks should run on Queue, but any listener that misses the implements ShouldQueue (which can be expressed by an empty Interface Should RunImmediately) is not queued at all, but will be executed in the old PHP line by line fashion - like an Action. So Events come with most of the Benefits of Actions, Testability, Single Responsibility; but introduce their own set of drawbacks. They are way harder to parse in mind, can hard to follow through multiple layers of events, and are even harder to test in combination than Actions.\nIf you want to offer some frustrating learning experiences for Developers new to the code, Silent 4 are using the same pattern and will listen for Model Events that are thrown automatically (this is the reason there is a $user-\u0026gt;saveQuietly() method).\nPipeline Pattern #If the steps that need to be performed are just running through a pre-defined set of classes - wouldn\u0026rsquo;t that be nice?\nclass UserController { public function register(Request $request) { $player = app(Pipeline::class) -\u0026gt;send($request) -\u0026gt;through([ // step 1: create the user \\App\\Pipes\\CreateUser::class, // step 2: Create the player \\App\\Pipes\\CreatePlayer::class // step 3: Prepare the Player for the game \\App\\Pipes\\InitatePlayer::class ]) -\u0026gt;thenReturn() -\u0026gt;get(); if (! $player) { return return view(\u0026#39;game.index\u0026#39;); } return view(\u0026#39;GamePage\u0026#39;, [\u0026#39;game\u0026#39; =\u0026gt; $player-\u0026gt;game]); } } This would be where I would state my experiences, advantages when designing, drawbacks on production - If I had any experience. Looking forward to someday building a pipeline pattern. If I ever do, I might come back here to update the post ;) However, I can give you some 5 on where to start understanding the pattern for yourself.\nSo what now? #The answer to the question \u0026ldquo;What pattern should I use?\u0026rdquo; is the same as for so many other questions in life: \u0026ldquo;it depends\u0026hellip;\u0026rdquo;. Every Pattern offers drawbacks, and every pattern has use cases in which it shines with all its advantages. In every use case there will be developers arguing there was a better pattern anyway, and some will see the bright side of the architect\u0026rsquo;s decision. For some over-the-thump-rules:\nOne single point in the app that stores Models? Repository Pattern Only need a bunch of methods to be reusable? Service Pattern A lot of reusable Code snippets that work very reliable? Action Pattern Something that may happen on the queue? Event Listener Pattern Wanna build something creative and tell me how it went? Pipeline Pattern Multiple things of the above? Use multiple patterns If you have more Patterns, or disagree with my opinion, feel free to send me some feedback. I am not the only one how had this idea, so check out what other people think too 6.\nHappy Coding Everyone :)\nThis Post offers some examples and sources\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHere is an example from Stack Overflow in which this is elaborated\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHere is one of the many Action favorable Posts. I learned the pattern using the book \u0026ldquo;Laravel beyond CRUD\u0026rdquo;.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLaravel Docs for more information\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA Tutorial to understand the basics, the Pipeline Docs, and an example of the Pipeline Pattern in Laravels Middleware Handling.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThis blog did similar things to refactor a controller in multiple ways.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"31 July 2022","permalink":"/posts/2022-07-action-and-other-patterns/","section":"Posts","summary":"Simple REST APIs are nice.","title":"About Actions, Jobs, Repositories, Events"},{"content":" Looking for a customer is the same process compared to looking for a job. I use the usual platforms to find companies that are looking for my tech stack and send a spontaneous application, maybe I get invited for an interview, maybe a technical interview with dev-related questions, or sometimes a coding challenge. In this post I want to look back on the technical questions I got asked. Interview Questions I remembered #The kind of questions I want to write about are not the \u0026ldquo;describe yourself in a three minutes\u0026rdquo; or \u0026ldquo;explain your experience\u0026rdquo; questions. I want to rethink some technical interview questions I was asked and could or could not answer at that point in time.\nLaravel Questions #What Laravel Feature do you love about Laravel 9? #That question should have been easy. One of the big features are the new accessors and mutators 1. I kinda dislike getters and setters anyway, so I don\u0026rsquo;t use them. The next big feature is the usage of Enums 2, which I don\u0026rsquo;t use in practice because I can\u0026rsquo;t use them as array keys, which might change in the future, but until that is fixed I get quite frustrated about this little drawback to honestly state it in an interview 3. Every other new feature I found very small, and the only one I am looking forward to using is the str() helper function which replaces the Str::of().\nWhat Feature do you miss about Laravel? #I think Laravel uses too many provider / list files that are not easier or less magic than other implementations. The auto-discovery of event listener 4 is one way to replace one provider with something easier; another feature that would get rid of the route file would the Spring (Kotlin Framework) inspired Route binding using Annotations / Attributes 5.\nIn PHP Annotations are often used (at least by me) to type-hint methods and properties. For example, if I define a relation in Laravel I type-hint the corresponding relation attribute call, now I have typed $game-\u0026gt;rounds() which returns a query builder, and $game-\u0026gt;rounds which returns the collection ($game-\u0026gt;rounds()-\u0026gt;get()).\n/** * @property \\Illuminate\\Support\\Collection rounds * @see \\App\\Models\\Game::rounds() */ class Game extends Model { public function rounds(): \\Illuminate\\Database\\Eloquent\\Relations\\HasMany { return $this-\u0026gt;hasMany(Round::class); } ... But since PHP 8, Attributes are a new feature. And they are offering quite some opportunities 6 7. Besides the inconvenient naming, I like the idea and can\u0026rsquo;t wait for Attributes to replace the route file 8. (For anyone who misses the route file for an overall overview has never seen a big route file and does not know the php artisan route:list command)\nuse Spatie\\RouteAttributes\\Attributes\\Get; class MyController { #[Get(\u0026#39;my-route\u0026#39;)] public function myMethod() { } } What standard changes or libraries do you apply to every Laravel Project? #Most times I join existing projects, and my private projects are most times to test something out and therefore focused on whatever I want to try out, and not follow my favorite Laravel styles. I will try to add something to this list, but if you have an answer to this question, I am curious to read it.\nClean up Laravel Sail and switch to Prostgres Not only because it saves some (for me usually not needed) Docker space, but because Prostgres is the better choice for a relational Database (Enums, Money Types, in-json search, (and the Docker Image works great for M1)).\nWrite a UUID Traid Because writing Str::uuid() on every model creation is annoying. I use uuids to obscure the id towards the client, but use the numeric id for relationships.\ntrait HasUuid { // fill uuid column protected static function booted() { static::created(fn ($model) =\u0026gt; $model-\u0026gt;uuid = Str::uuid()); } // set route key name public function getRouteKeyName() { return \u0026#39;uuid\u0026#39;; } } How does a request live through Laravel? #One of my favorite questions - so I spend some time digging into the Laravel Code to find out.\nStarting the Application public/index.php\nLaravel said $kernel = $app-\u0026gt;make(Kernel::class); and there was a Kernel. Out of the box, this is the app/Http/Kernel.php. In this step the Application (which holds path information, registers Providers\u0026hellip;) 9 and Router (which is the class behind Route Facade) are instantiated.\nHandling app/Http/Kernel.php The Kernel extends vendor/laravel/framework/src/Illuminate/Foundation/Http/Kernel.php, and the important method call is handle(). In the handle function the Kernel tries to send the Request through the Router, configure error handling, configure logging, and detect the application environment. After this, and before the call returns the response the RequestHandled Event is dispatched.\nPipelines app/Http/Kernel.php\nThe Pipeline Design Pattern is a software design pattern that provides ability to execute a sequence of operations where data flows through a sequence of tasks or stages. 10\nEvery Middleware in Laravel is a pipe the request is sent though and a small task is performed on the Request. In this step the HTTP Session, CSRF Token, Maintenance Prevention, and whatever Middleware you added in the Kernel.\nDispatch to Router vendor/laravel/framework/src/Illuminate/Routing/Router.php\nThe Router matches the Route from the Routes defined in the routes/* files (or other places if specified), dispatches a RouteMatched Event, and again uses a Pipeline to run through the Route specific Middlewares which might include Authentication or Authorisation.\nRun route, run vendor/laravel/framework/src/Illuminate/Routing/ControllerDispatcher.php\nThe Route matches its Controller or Callback, whatever convention was followed. Then the Controller Dispatcher tries to satisfy the Method Dependencies 11, e.g. if you injected a Repository or FormRequest. For every Parameter (besides the Model Bindings), a Reflection Class is created and after that an Instant of that class is made. Some magic later the FormRequestServiceProvider kicks in (what here happens is Container Magic. Laravel Container are something interesting, something that cause itchy bugs, and something I need to dedicate learning time to understand - so this is magic for me at the current point in time).\nValidation vendor/laravel/framework/src/Illuminate/Foundation/Providers/FormRequestServiceProvider.php\nThe Validation is triggered in the vendor/laravel/framework/src/Illuminate/Validation/ValidatesWhenResolvedTrait.php first checking the Authorization, followed by the Validation. If either is not specified, a default is created.\nController\nAfter the Dependency Injection of everything the Controller needs, the business code is executed, the Controller returns e.g. a Resource.\nWrapping into a Response vendor/laravel/framework/src/Illuminate/Routing/Router.php\nThe Response is wrapped into a Response again in the Router - so from Code Perspective we are already on the way back. From that point on there is not much more to write, the Response bubbles up the way it came and is returned to the Kernel in which it is the (Symfony) Response to build Header and Body and send the information.\nPHP Questions #What PHP 8 Feature do you like the most? #A lot! Using Laravel examples:\nConstructor Properties, especially for Events: Method parameters can now include the declaration of public and private properties.\nclass PlayerJoined { public function __construct(public Game $game, public Player $player) { } } Union Types are great for Events as well\nclass UpdatePlayerInformation { public function handle(PlayerJoined|PlayerLeft $event): void { } } Nullsafe Operator is just neat. $player-\u0026gt;user ? $player-\u0026gt;user-\u0026gt;name : null = $player?-\u0026gt;user-\u0026gt;name\nMatch Expression a bit better switch statement\n$score = match ($playerRole) { \u0026#39;WEREWOLF\u0026#39;,\u0026#39;MINION\u0026#39; =\u0026gt; $werewolfScore, \u0026#39;TANNER\u0026#39; =\u0026gt; $tannerScore, \u0026#39;WATCHER\u0026#39; =\u0026gt; 0, default =\u0026gt; $villagerScore, }; // match(true) is the same half shady, half awesome solution as switch(true) $score = match (true) { $diffFromTarget \u0026lt;= 5 =\u0026gt; 10, $diffFromTarget \u0026lt;= 10 =\u0026gt; 3, $diffFromTarget \u0026lt;= 20 =\u0026gt; 1, default =\u0026gt; 0, }; Dev Tool Questions #Your Query is slow, how to tackle the task to improve it? #A basic, \u0026ldquo;do you know your tools?\u0026rdquo; question.\nWhat can cause long client-side waiting time? Client Issues, long boot time on Laravel side, long Query time, third Party Api calls \u0026hellip; The Flow Chart I would follow would like: Is it a Backend problem? Can I replicate the\nHow can I debug performance? Simulate on Dev Environment (Seeders, Feature Tests), Postman debugging, Laravel Debug bar 12, Logging of benchmarks, Logging with third party analytics (e.g. Performance logging in Sentry)\nBonus hint if you don\u0026rsquo;t use the Debugbar: Illuminate fires an illuminate.query Event that you can listen for ( preferably in a Service Provider).\nEvent::listen(\u0026#39;illuminate.query\u0026#39;, fn($query) =\u0026gt; var_dump($query)); Laravel 9 has new Accessors and Mutators\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLaravel 9 has new Enums\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nYou can not use Enums as Object keys, discussed here\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLaravel offers great Auto Discovery of Events that I prefer over EventServiceProvider\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSpring offers a nice way for route binding using Annotations -\u0026gt; Spring Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSome more infos on Attributes at wiki.php\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBest in Depth Article about Attributes\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThere is a spatie package which implements what I want, I just hope it will find a way in the \u0026ldquo;Laravel way of working\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe Laravel Application corresponds to the Service Container\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGreat Article about Pipeline usage in Laravel\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLearn more about Dependency Injection in Controller in the Laravel Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAwesome Feature every Laravel Developer should use here on GitHub\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2 June 2022","permalink":"/posts/2022-06-customer-search/","section":"Posts","summary":"Looking for a customer is the same process compared to looking for a job.","title":"Technical Job Interview questions 2022"},{"content":" Driver-based Development is a coding pattern that is common in the Laravel world and used in multiple instances in the framework. It\u0026rsquo;s important to understand how Drivers and Managers work to understand how the framework solves some problems, but it\u0026rsquo;s also a nice pattern to keep in mind for example to write tests that usually work with third-party APIs Manager and Driver Pattern (ad other Patterns) #I started the research for this post to learn more about the software patterns. After my last learning on the usage of the Repository Pattern in this post about something similar to the Repository Pattern. So to keep this from happening, I want to give a small overview of the patterns that crossed my research path. This resulted in some learning, some confusion, and a somewhat understanding of the different patterns that people associated with the Driver Pattern. Keep in mind, in the end, Software Patterns are proven concepts that solve common problems in programming.\nBuilder Pattern #The Builder Pattern enables the build-up of complex objects, the most common example would be the ORM Eloquent. Every Laravel developer has used it to build the complex object representation of a SQL query. Another example are Laravel Factories, which also use a number of methods to create a complex object in a readable way. I recommend this post to learn more.\n$users = User::factory() -\u0026gt;has(Post::factory()-\u0026gt;count(3)) -\u0026gt;suspended() -\u0026gt;make(); Provider Pattern #The Provider Pattern has more definitions than I expected\u0026hellip; It can refer to the Data Provider pattern I used in Flutter and Angular to store and hold data; it may refer to the encapsulation of methods that do different things like a plugin or STK; or in the Laravel world Provider refer to application bootstrapping and configuration, they register routes, singletons, or bind listeners to events. I recommend asking the person who mentioned it to explain to what they refer.\nFactory Pattern #The Factory Pattern (not Laravel Factories!) enables the creation of various types of objects on runtime. The decision on which precise class to create is done during runtime, but usually the same in different environments. It can be powerful if you don\u0026rsquo;t know which type of object to create, e.g. if the client may decide this; or you want to have the creation of multiple objects in one class to localise them or share functions they both need. I recommend this post to learn more\nProductFactory::build(\u0026#39;Computer\u0026#39;); The Driver Pattern in contrast to all of them #Different Drivers enable different implementations to perform the same tasks. The most common example is sending messages using different services. A driver could be sms, one mail, and one push notification. The task is always sending the message to the given set of users, but the implementation is different, other third-party APIs might be used and sometimes the decision of which driver to use is done on runtime. Another example in the Laravel world is the Cache Driver that stores your cache in redis or table, or the Database Driver that translates your Eloquent to mySql or pgsql.\nMessage::channel(\u0026#39;mail\u0026#39;) -\u0026gt;to($user) -\u0026gt;content(\u0026#39;Do not think about pink elephants\u0026#39;) -\u0026gt;send(); Now about the different Patterns: This code utilizes the Builder Pattern to set the properties of the object step by step, but the Driver Pattern Magic happens just in the first line which determines how the message is sent. In the Driver class itself somewhere the implementation of the sending must be, and there I would call some Service class or library for actually sending emails and another one for sending SMS. The Factory Pattern might look similar at first sight as it also creates an object on runtime based on a string, but the Factory Pattern aims to instantiate Models while the Driver Pattern aims to instantiate classes that offer defined functionalities.\nWhen to use a Driver Manager Solution #The most common answer to this question I found was:\nA driver-based service is the right choice when the same utility can be provided by more than one technology. Source\nSo whenever you discover a problem that might now (or in the future) be solved by multiple or changing technologies, this pattern can make it easy and simple to switch between the technologies depending on runtime decisions, database entries, or environment variables.\nBut there is more! I want to emphasize two other options when this pattern can be a handy tool:\nTesting and local development can be a non-trivial task if you use third-party APIs or your own Micro Services. During tests (and sometimes during local development) you don\u0026rsquo;t care about the correctness of the technology you are using, and maybe don\u0026rsquo;t even want to trigger any outside communication. Based on your Environment (testing or local) you can then switch to a FakerDriver that maybe can be configured in the test to simulate a long request, a wrong answer, or just correct behavior.\nA-B Testing of Services The first time I came in contact with this pattern, one of the reasons (besides many others) why we went for this pattern was the easy implementation of an A-B Test of a new Recommendation System. In a situation in which you have two technologies to do the same job, but want to compare how the users react to both of them you can implement a Driver pattern to let different users use different technologies and compare the individual engagement rate of features for different user groups.\nImplementation #Folder Structure #Here is the plan: The two Driver are FakeDriver and HugoDriver (No need to search for that name, I just made it up). To ensure the next developer who implements a Driver will implement everything we need, the RecommenderContract defines which methods should be in a Driver. The RecommenderManager is the file in which we define which string causes the instantiation of which Driver, and which Driver is the Default. And the Recommender is the Facade we will be using in practice.\nSupport └─── Drivers │ │ RecommenderContract.php │ │ FakeDriver.php │ │ HugoDriver.php │ └─── Facades │ │ Recommender.php │ └─── Managers │ RecommenderManager.php To now understand the implementation I would like to follow the code starting with the usage I aim for.\n// using default driver Recommender::recommendationsForUser($user); // using custom driver Recommender::driver(\u0026#39;hugo\u0026#39;)-\u0026gt;recommendationsForUser($user); Facade #To achieve this code, we first need a Laravel Facade. This Facade will call the Recommender Manager.\nIn a Laravel application, a facade is a class that provides access to an object from the container. The machinery that makes this work is in the Facade class. Laravel\u0026rsquo;s facades, and any custom facades you create, will extend the base Illuminate\\Support\\Facades\\Facade class.\nAs so often I recommend to type-hint all methods to utilize autocompletion as well as the possibility to \u0026ldquo;click through\u0026rdquo; your code easily.\nuse Illuminate\\Support\\Facades\\Facade; /** * Class Recommender * * @method recommendationsForUser(array $models, ?int $userId = null) * @see \\App\\Support\\Drivers\\HugoDriver::recommendationsForUser() * @method driver(string $name) * * @see \\App\\Support\\Managers\\RecommenderManager */ class Recommender extends Facade { protected static function getFacadeAccessor() { return RecommenderManager::class; } } Manager #The Manager defines which Driver is initiated. For this extend the Illuminate\\Support\\Manager. To implement this class you need to define the method getDefaultDriver. If you want a different default per environment, this would be the place to either return a config value or an environment variable. Then you need one method per Driver you want to build. The Illuminate Manager will guess the method name based on the string you put in (e.g. 'fake') using $method = 'create'.Str::studly($driver).'Driver';.\nuse Illuminate\\Support\\Manager; class RecommenderManager extends Manager { public function getDefaultDriver(): string { return env(\u0026#39;RECOMMENDER_DRIVER\u0026#39;, \u0026#39;fake\u0026#39;); } public function createHugoDriver(): HugoDriver { return new HugoDriver(); } public function createFakeDriver(): FakeDriver { return new FakeDriver(); } } One step is missing until this is working - registering the Manager. This is done using a Laravel Service Provider. As I don\u0026rsquo;t plan to use the Recommender functionality in every request I made it a deferred Provider.\nIf your provider is only registering bindings in the service container, you may choose to defer its registration until one of the registered bindings is actually needed. Deferring the loading of such a provider will improve the performance of your application, since it is not loaded from the filesystem on every request.\nuse Illuminate\\Support\\ServiceProvider; use Illuminate\\Contracts\\Support\\DeferrableProvider; class RecommenderServiceProvider extends ServiceProvider implements DeferrableProvider { public function register(): void { $this-\u0026gt;app-\u0026gt;singleton(RecommenderManager::class, fn ($app) =\u0026gt; new RecommenderManager($app)); } public function provides(): array { return [RecommenderManager::class]; } } Driver #The Facade calls the Manager, and the Manager decides which Driver to call, now the Driver is missing implementation. This is very straightforward. Whatever Hugo does, Hugo does it here!\nuse Illuminate\\Support\\Collection; class HugoDriver implements RecommenderContract { public function recommendationsForUser(array $models, ?int $userId = null): Collection { // implement magic here return collect([]); } } Additional #As I mentioned I use this to test my code if it utilises third-party technology. So when I write a FakeDriver I implement additional methods, that allow me to fake different states, time delays, or other things. Sure, you can also write tiny Unit Tests to test such behaviors, I made the best experience with feature tests and this method of faking data during the tests.\nHappy Coding #This was my two cents on Manager and Drivers, and the way I implemented it. When I discovered the pattern I read through this post by Orobo, as well as this on by Valerio.\nIf you spot an error, please don\u0026rsquo;t hesitate on enlighten me,\nHappy Coding :)\n","date":"22 May 2022","permalink":"/posts/2022-05-driver-manager-pattern/","section":"Posts","summary":"Driver-based Development is a coding pattern that is common in the Laravel world and used in multiple instances in the framework.","title":"Manager and Driver Pattern - pattern, implementation, and usage"},{"content":" Programmer giving Relationship Advice - A summary about Laravel / Eloquent relationships including some hints, advanced techniques to use and misuse relations Relationships are great #Relational Databases like mySql or postgres tend to have that thing called relations. There are used in almost all Laravel Projects with a database and most Laravel developers know them and know how to use them. But not every developer knows the Laravel Docs by heart and there are even some features that are not mentioned in the Laravel Docs at all, but can only be discovered by clicking through the Eloquent code.\nThis blog post wants to sum up the basic relations Eloquent offers, hinting at some special ways to define relations and advanced techniques to create relations that might be useful for querying. However, this post does not cover the usage of relations, their benefits for query optimization, or general explanations of how they work (for learning that I recommend the Laravel Docs or this Blog Article) - only the definition of them.\nExample Database structure #Let\u0026rsquo;s play a game, shall we? Let\u0026rsquo;s have some games, each with a hostPlayer, some players who belong to a game and a user. A game consists of multiple rounds, in each round one player is active, and all players may make a move resulting in a score per round.\nClass diagram # classDiagram Move --\u003e Round : Round has many Moves, Move belongs to a Round Round --\u003e Player : Player has many Rounds as Active-Player, Round belongs to an Active-Player Round --\u003e Game : Game has many Rounds, Round belongs to a Game Move --\u003e Player : Player has many Moves, Move belongs to a Player Player --\u003e Game : Game has many Players, Player belongs to a Game Game --\u003e Player : Player has many Games as Host, Game belongs to a Host-Player class Game { id host_player_id started_at } class Player { id game_id user_id color } class Round { id game_id active_player_id completed_at } class Move { id round_id player_id score } One to One #HasOne and BelongsTo #If a model has a column containing another model\u0026rsquo;s id, forming a One to One Relationship. Every Relationship has its inverse form - if a User HasOne Level, a Level BelongsTo a User. A Model with a HasOne says \u0026ldquo;the id of mine is in on another table\u0026rdquo;, the standard example would be:\nclassDiagram User \u003c-- Level: User has one Level Level belongs to User class User { id email password } class Level { id user_id over_all_score } class User extends Model { public function level(): \\Illuminate\\Database\\Eloquent\\Relations\\HasOne { return $this-\u0026gt;hasOne(Level::class); } ... } class Level extends Model { public function user(): \\Illuminate\\Database\\Eloquent\\Relations\\BelongsTo { return $this-\u0026gt;belongsTo(User::class); } ... \u0026ldquo;Creative\u0026rdquo; usage of the extra Parameters #A word on parameter naming The something_id column is called foreign_id, while the id column of this model is referred to as local_id; the model to which this foreign_id belongs is the owner model, and its id column is referred to as owner_id. In Laravel it is possible to enter alternative values (other than Laravel\u0026rsquo;s guessed values $this-\u0026gt;belongsTo(User::class, 'user_id', 'id')) for reasons like using uuids or naming conventions.\nBut you can use these parameters also in more creative ways, let\u0026rsquo;s say you want to display the level of the user next to a players icon:\nclass Player extends Model { public function level(): \\Illuminate\\Database\\Eloquent\\Relations\\HasOne { return $this-\u0026gt;hasOne(Level::class, \u0026#39;user_id\u0026#39;, \u0026#39;user_id\u0026#39;); } ... The idea of \u0026ldquo;misusing\u0026rdquo; relations in this way is considerable, strange, not intuitive for readers, and confusing for beginners - so maybe just don\u0026rsquo;t do them. With this blog post I just want to point out, that this way of working with relationships is possible, works for some cases great, and is kinda fun to think about. If I need the relation (for eager loading, query optimization\u0026hellip;) it is handy to take the shortcut of just using the user_ids. The problems I want to point out:\nUsing the create function will not create a user, and honestly, I have no idea what would happen or which id would be set there This query will not check if the user exists or is deleted Default Models #Both HasOne and BelongsTo relations may have a default which (for example for a level) comes in handy because you don\u0026rsquo;t have to store a model for a user who maybe never plays a game.\npublic function level(): \\Illuminate\\Database\\Eloquent\\Relations\\HasOne { return $this-\u0026gt;hasOne(Level::class)-\u0026gt;withDefault([\u0026#39;overall_score\u0026#39; =\u0026gt; 0]); } One To Many #HasMany and BelongsTo #The more common One to Many relations are indistinguishable from a database perspective (if there is no unique constraint on the foreign key column). The difference is the possibility of the Owner to have more than one model belonging to it.\nclass Game extends Model { public function rounds(): \\Illuminate\\Database\\Eloquent\\Relations\\HasMany { return $this-\u0026gt;hasMany(Round::class); } ... } class Round extends Model { public function game(): \\Illuminate\\Database\\Eloquent\\Relations\\BelongsTo { return $this-\u0026gt;belongsTo(Game::class); } ... Queries in Relations #Compared to ofMany adding extra queries on the relation is possible as well and can come in quite handy:\nclass Game extends Model { public function redPlayers(): \\Illuminate\\Database\\Eloquent\\Relations\\HasMany { return $this-\u0026gt;hasMany(Player::class)-\u0026gt;where(\u0026#39;color\u0026#39;, \u0026#39;red\u0026#39;); } public function playersWithoutMove(): \\Illuminate\\Database\\Eloquent\\Relations\\HasMany { return $this-\u0026gt;hasMany(Player::class)-\u0026gt;whereDosntHave(\u0026#39;move\u0026#39;); } ... } Using HasOne-\u0026gt;ofMany #But HasOne also offers great options if you are often looking for one special model of a HasMany Relationship. This use case is very common, so I think the ofMany function is underrated.\nclass Round extends Model { // latest (current) Move public function latestMove(): \\Illuminate\\Database\\Eloquent\\Relations\\HasOne { return $this-\u0026gt;hasOne(Move::class)-\u0026gt;latestOfMany(); } // best Move public function latestMove(): \\Illuminate\\Database\\Eloquent\\Relations\\HasOne { return $this-\u0026gt;hasOne(Move::class)-\u0026gt;latestOfMany(\u0026#39;score\u0026#39;, \u0026#39;max\u0026#39;); } // best, latest move where score is positive public function bestLatestMoveWithPositiveScore(): \\Illuminate\\Database\\Eloquent\\Relations\\HasOne { return $this-\u0026gt;hasOne(Move::class)-\u0026gt;ofMany( [\u0026#39;created_at\u0026#39; =\u0026gt; \u0026#39;max\u0026#39;, \u0026#39;score\u0026#39; =\u0026gt; \u0026#39;max\u0026#39;], fn ($query) =\u0026gt; $query-\u0026gt;where(\u0026#39;score\u0026#39;, \u0026#39;\u0026gt;\u0026#39;, 0); ); } ... \u0026ldquo;Creative\u0026rdquo; One to Many Relations #Breaking it down to the minimal requirement, a HasMany relation requires that there is another table, which holds an identifier that the local table holds as well.\nIf you look at our class diagram, for example, there is no direct connection between Move and Game, if you want the moves of a game you have to use the Round as a middleman. Now let\u0026rsquo;s say I want a statistic that proves that my game is fair and that the host player does not make moves with higher scores or so - whatever reason I might have to create such a relation.\nclass Game extends Model { public function hostPlayerMoves(): \\Illuminate\\Database\\Eloquent\\Relations\\HasMany { return $this-\u0026gt;hasMany(Moves::class, \u0026#39;player_id\u0026#39;, \u0026#39;host_player_id\u0026#39;); } ... Again, creating this kind of relationships might be smelly or hacky, but it can be handy if you keep the possibilities in mind that relations offer. Having Things Through #Laravel provides a relation for two consecutive HasMany relations.\nclassDiagram Round --\u003e Game : Game has many Rounds, Round belongs to a Game Move --\u003e Round : Round has many Moves, Move belongs to a Round Move \u003c-- Game : Game has many Moves through Round class Game { id host_player_id started_at } class Round { id game_id active_player_id completed_at } class Move { id round_id player_id score } class Game extends Model { public function moves(): \\Illuminate\\Database\\Eloquent\\Relations\\HasManyThrough { return $this-\u0026gt;hasManyThrough(Move::class, Round::class); } ... \u0026ldquo;Creative\u0026rdquo; HasManyThroughs #Let\u0026rsquo;s say we want to display the Level of the overall Game - maybe to match with other Games or whatever. Again we can use the additional parameters to skip some tables on the way between Game and Level. Usually, we would start at the Game, and look for the players, look for the users, look for the levels. But both the levels and the players share the same user_id - why not skip the User?\nclass Game extends Model { public function levels(): \\Illuminate\\Database\\Eloquent\\Relations\\HasManyThrough { return $this-\u0026gt;hasManyThrough( Level::class, Player::class, \u0026#39;game_id\u0026#39;, // Foreign key on the players table \u0026#39;user_id\u0026#39;, // Foreign key on the levels table \u0026#39;id\u0026#39;, // Local key on the games table \u0026#39;user_id\u0026#39; // Local key on the players table ); } ... Again, creating this kind of relationships might be smelly or hacky, but it can be handy if you keep the possibilities in mind that relations offer. Many To Many #Many to Many relations are the kind of relations that require a pivot table. If compared to the implementation depicted in the examples above, where a user has a player per game I could have implemented a Many to Many relation using a game_user or game^user or games_2_users table or other conventional namings for pivot tables. That would look like this:\nclass Game extends Model { public function player(): \\Illuminate\\Database\\Eloquent\\Relations\\HasManyThrough { return $this-\u0026gt;belongsToMany(User::class, \u0026#39;game_user\u0026#39;); } ... The point I don\u0026rsquo;t like about this is #1 the naming convention does not reflect the meaning of the relation; I prefer calling a thing by their name, in this case, players. 2# The first thing especially bugs me after you start adding more columns in the pivot table, starting with timestamps, then maybe a soft delete, and then a custom link or so. At some point, a lot of the pivot tables I saw would have looked cleaner, and caused less code smell if they were models from the very beginning.\nThis does not mean, that many to many relations are useless. As I mentioned in the last examples, there are many ways to use the additional parameters in the relationship functions. So if you see Player as a pivot model, you can still define this relation:\nclass Game extends Model { public function users(): \\Illuminate\\Database\\Eloquent\\Relations\\BelongsToMany { return $this-\u0026gt;belongsToMany( User::class, // target model \u0026#39;players\u0026#39;, // pivot table \u0026#39;game_id\u0026#39;, // Foreign key on pivot player table \u0026#39;user_id\u0026#39;, // Foreign key on pivot player table \u0026#39;id\u0026#39;, // Parent key on the games table \u0026#39;id\u0026#39; // Related key on the users table ); } ... Any table with two foreign ids may be used as a pivot table!\n\u0026ldquo;Creative\u0026rdquo; Many to Many Relations #You may again use this information even further and again create sometimes useful relations by using the additional function parameters. For example, if you want to have the Levels instead of the Users of a Game.\nclass Game extends Model { public function levels(): \\Illuminate\\Database\\Eloquent\\Relations\\BelongsToMany { return $this-\u0026gt;belongsToMany( Level::class, // target model \u0026#39;players\u0026#39;, // pivot table \u0026#39;game_id\u0026#39;, // Foreign key on pivot player table \u0026#39;user_id\u0026#39;, // Foreign key on pivot player table \u0026#39;id\u0026#39;, // Parent key on the games table \u0026#39;user_id\u0026#39; // Related key on the levels table ); } ... Last words #This was a collection of infos, hints, and hacks about the definition of Laravel or Eloquent Relationships. If you found any mistakes or have additional tricks please feel free to contact me :D\nHappy coding\n","date":"20 May 2022","permalink":"/posts/2022-05-relationships/","section":"Posts","summary":"Programmer giving Relationship Advice - A summary about Laravel / Eloquent relationships including some hints, advanced techniques to use and misuse relations Relationships are great #Relational Databases like mySql or postgres tend to have that thing called relations.","title":"Useful and Useless Relationship Definitions"},{"content":" Scopes are nice, but by extending the Eloquent Builder for a Model enables you to add custom, model-specific methods that are often used or should have a central definition Scopes are great, but \u0026hellip; #Local scopes allow you to define common sets of query constraints that you may easily re-use throughout your application; read more in the Laravel Docs. Also, if you want to have a definition of a scope in one central place to maybe come back and change in at one place, instead of everywhere - a common example in practise is an activeUser scope (email confirmed? password not older than one year? \u0026hellip; ).\nScopes are great, but have two major drawbacks from my point of view: #1 no autocompletion / no \u0026ldquo;jump in your code by clicking\u0026rdquo; on it, no type hinting. This is because drawback #2 they are executed by Laravel magics. The Framework checks if the method you are trying to call is defined in scope\u0026lt;yourMethodNameInCamelCase\u0026gt; in the model and uses it then.\nAbout Patterns #Laravel Scopes are build utilizing the Builder Pattern, which enables the build-up of complex object (in this case the object representation of a SQL Query) step by step using methods to change the query bit by bit. Now, scopes are also following the pattern but in use cases in which a set of queries if performed often, they make the code more readable and maintainable.1\nRepository Pattern #One pattern is partially similar, the Repository Pattern was the closest I could find. Most times the Repository handles create, delete, and index methods, while this post focuses on index / query methods only. The only I could not find a specific Pattern I could match the custom query builder with, but\nThe Repository is an abstraction Layer of Data, from this abstraction Layer the data may be retrieved using function like Post::getAll() or in the case of Eloquent Post::all(). Most implementations of the Repository pattern I found are doing the above step of overwriting Eloquent methods with their own getAll method. But instead of overwriting the Eloquent methods, why not just extend them? 2\nWriting a Custom Builder that Extends the Eloquent Builder #The Builder that Laravel uses behind every ::query() is the Illuminate\\Database\\Eloquent\\Builder. A class that extends this Builder for one Model offers the opportunity to add custom methods to the Builder.\nCompared to Scopes I want to highlight, that neither the Scope Prefix is needed, nor the $query parameter. Additionally, this utilises the fully typed / auto-completion feature I value so much 3.\nnamespace App\\Models\\Builders; use App\\Models\\User; use Illuminate\\Database\\Eloquent\\Builder; /** * @template TModelClass of \\App\\Models\\Post * @extends Builder\u0026lt;TModelClass\u0026gt; */ class PostBuilder extends Builder { public function published(): self { return $this-\u0026gt;where(\u0026#39;published\u0026#39;, 1); } public function whereHasMedia(): self { return $this-\u0026gt;where(fn (self $query) =\u0026gt; $query -\u0026gt;whereHas(\u0026#39;image\u0026#39;) -\u0026gt;orWhereHas(\u0026#39;video\u0026#39;) ); } public function visibleToUser(User $user): self { return $this-\u0026gt;published() -\u0026gt;where(fn (PostBuilder $query) =\u0026gt; $query -\u0026gt;where(\u0026#39;privacy\u0026#39;, \u0026#39;public\u0026#39;) -\u0026gt;when($user-\u0026gt;isAdmin(), fn (PostBuilder $query) =\u0026gt; $query -\u0026gt;orWhere(\u0026#39;privacy\u0026#39;, \u0026#39;friends\u0026#39;) ) ) ); } } This will not work out of the box, how should Laravel know that we don\u0026rsquo;t want to use the Eloquent Buidler?\nTo solve this we first have to overwrite the query Method to get the Typehints and autocompletion. Secondly we have to overwrite the Model newEloquentBuilder method. Inside the Illuminate\\Database\\Eloquent\\Model this methods usually initiates a new \\Illuminate\\Database\\Query\\Builder using the $query parameter. As our PostBuilder extends this Class, we can just use it the same.\nclass Post extends Model { /** * @return PostBuilder\u0026lt;\\App\\Models\\Post\u0026gt; */ public static function query(): PostBuilder { return parent::query(); } /** * @param \\Illuminate\\Database\\Query\\Builder $query * @return PostBuilder\u0026lt;\\App\\Models\\Post\u0026gt; */ public function newEloquentBuilder($query): PostBuilder { return new PostBuilder($query); } ... Enjoy the Usage #Let\u0026rsquo;s feel the joy of what we have implemented:\n$posts = Post::query() -\u0026gt;visibleToUser(Auth::user()) -\u0026gt;paginate(); $latestPostedImage = Post::query() -\u0026gt;where(\u0026#39;user_id\u0026#39;, 41) -\u0026gt;whereHasMedia() -\u0026gt;published() -\u0026gt;latest() -\u0026gt;first(); $latestPostedImage = $user-\u0026gt;posts()-\u0026gt;published()-\u0026gt;first(); $userWithPublishedPosts = User::query() -\u0026gt;whereHas(\u0026#39;post\u0026#39;, fn (PostBuilder $query) =\u0026gt; $query-\u0026gt;published($user)) -\u0026gt;get(); Can you feel it? No, you can\u0026rsquo;t - you have to try it to get the satisfying feeling of your IDE proposing the Model-dependent extra methods like \u0026lsquo;published\u0026rsquo; while typing, or when you go through old or unknown code the possibility to click on the method and get directly to the implementation without any Laravel Plugin or searching for a ScopeMethod.\nThere a some additional things to mention:\nIf you don\u0026rsquo;t use the query Method (like Post::first()) the newEloquentBuilder Method will be called anyway, but you don\u0026rsquo;t have Typehints Usage of the two patterns are the same, the main different is the way ScopeMethods are implemented and the two extra Methods in the Model In case your super high complexity Project can utilize it: Builder classes may share traits ;) Bonus: #If custom query builders is not enough for you to play with, try customising Collections 4. If there is any set of collection methods you always use, or you are missing, you can just extend the Laravel Collections yourself!\nclass AppServiceProvider extends ServiceProvider { public function boot() { Collection::macro(\u0026#39;firstWhereMin\u0026#39;, fn (string $key) =\u0026gt; $this-\u0026gt;firstWhere($key, $this-\u0026gt;min($key))); } } I am still looking for a nice way to keep my beloved autocompletion, but for just the functionality I can recommend you to just write all the Collection methods you might miss. 5\nBonus hin: custom Collections #Next to the custom query builder, Laravel allows to also have customized the collections that get instntiated when e.g. a HasMany Relation is called without brackets or a query is call using get(). 6\nuse Illuminate\\Database\\Eloquent\\Collection; class PostCollection extends Collection { public function published(): self { return $this-\u0026gt;filter(fn (Post $post) =\u0026gt; $post-\u0026gt;published_at); } } class Post extends Model { public function newCollection(array $models = []): PostCollection { return new PostCollection($models); } } In this post I write more about patterns\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIn my personal point of view the only reason to completely implement this pattern is to generate everything starting from routes, to controller, and resources based on an openApi file or so, but here is an example\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhen I looked through the web, the only blog articles I could find, which did implement this pattern where this one by Martin Joo and this one by Tim MacDonald. Both do not overwrite the query method, but every thing else is quite similar to this post.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRead through the Laravel Docs regarding this\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSpatie has a package with nice examples if you are looking for something pre-build or inspiration\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFound in this book which refers to quite some topics I like: LARAVEL BEYOND CRUD by Brent Roose\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"14 May 2022","permalink":"/posts/2022-05-custom-query-builder-pattern/","section":"Posts","summary":"Scopes are nice, but by extending the Eloquent Builder for a Model enables you to add custom, model-specific methods that are often used or should have a central definition Scopes are great, but \u0026hellip; #Local scopes allow you to define common sets of query constraints that you may easily re-use throughout your application; read more in the Laravel Docs.","title":"Model Specific Query Builder - an Alternative to Scopes"},{"content":" I got the task to implement a Demo environment, learned something about Laravel Factories and the usage of an environment to give possible customers / investors a taste of your product and the developers to find response time / query problems and UX bugs A \u0026ldquo;Demo\u0026rdquo; Feature Request #This card was proposed in a sprint planning and sparked a discussion around multiple problems and ideas.\nAs a future Analytics-Component User I want to see a version of the Analytics-Component fully functional with generated data, so that I can see how the page would look like, before I buy the Analytics Component\nFirst, the ideas: this company sold a software platform with one of its components being a set of graphs, statistics, and informative texts to display the usage of the other platform features. The Analytics Component was not meant for intern analytics, but a feature set for business customers. Allowing business customers to play around with such a page before making decisions is a nice to have feature - who dislikes demos? A nice demo page is reachable for the interested customer, can\u0026rsquo;t break - even if the customer has no idea what they are doing, and should display as many features as possible accurately, up-to-date, and in sense-full context.\nThen, the discussion: We sure will not re-build the multi-page Analytics Component with some mocked graphs to only forget about updating it whenever we add a page to the real product. After some discussion we want to generate (only the needed) data to display all graphs and information correctly, but sure don\u0026rsquo;t want any of it to be in our production database. So we decided the best thing to do is to set up a demo environment that became part of our pipelines and would receive the same features while holding the maximum workload one customer could cause. The demo account would be reachable to potential customers by offering the demo user credentials and link to the environment, so the future customer could play around with the page without breaking anything.\nImplementation #Setting up a cost-efficient small server, building some pipelines, and branching a new \u0026lsquo;demo\u0026rsquo; branch from master. Before starting the implementation I would like to set some constraints on the task. The Analytics Component could was displaying data starting from yesterday, and keep historical data up to one year. The data required was a mix of multiple models - a great thanks to the business for allowing the dev team to refactor most of the respective data to an Event-Sourced pattern some weeks ago. The Component should work and display data every day, so there had to be a job to generate new data every night. So what I build was:\nA Command triggered by every deployment to re-generate the data if needed, e.g. if a feature changed an additional data had to be generated A Job to run every night (as nobody was relying on the server one slow job would be fine). This job generates new data every day, and deletes every data that is older than a year. Laravel Usage of Factories # Laravel Learning: Cascading Factories Factories are a great way to generate data. One problem I run into was writing a factory that could also generate the corresponding EventS-ource Model. Event Sourcing in one sentence describes a pattern in which the changes of a state are stored in a database. Imagine we have Users who can collect Experience Points by playing Games. Instead of increasing a column in the users table, or summing up the score column of the games table (because maybe there are more ways to earn points), we create a table experiences which holds the user who earned points, the cause of points and the number of points earned. This can be a great pattern if you plan on having some analytics (which then only need to query one table), or want to leverage the \u0026ldquo;event\u0026rdquo; part of the pattern and have multiple background/ async jobs happening whenever the state is changing.\nThe corresponding factory to generate games with experiences would be:\nclass GameFactory extends Factory { protected $model = Game::class; public function definition(): array { return [ \u0026#39;user_id\u0026#39; =\u0026gt; User::factory(), \u0026#39;score\u0026#39; =\u0026gt; random_int(0, 100), ]; } public function withExperience(): self { return $this-\u0026gt;afterCreating(fn (Game $game) =\u0026gt; Experience::factory()-\u0026gt;create([ \u0026#39;game_id\u0026#39; =\u0026gt; $game-\u0026gt;id, \u0026#39;user_id\u0026#39; =\u0026gt; $game-\u0026gt;user_id, \u0026#39;created_at\u0026#39; =\u0026gt; $game-\u0026gt;created_at, \u0026#39;updated_at\u0026#39; =\u0026gt; $game-\u0026gt;updated_at, ])); } } And it could be used like this:\n$game = Game::factory()-\u0026gt;withExperience()-\u0026gt;create(); About generating data with context #Generating random data is tricky. There are some learnings I want to share while I wrote the job:\nWhenever it makes sense, after generating a bunch of models I invalidated and soft-deleted a subset of those. This helped to get a realistic view and I hoped I could spot a bug if did so. When working with data created every day I had a look at the average user - in this case people were more active on weekdays compared to weekends. This is no simulation, I avoided holidays or anything, but a small line with the integrated Carbon function was easy enough to give some realistic flow in the data $date-\u0026gt;isWeekend() ? random_int(2, 15) : random_int(45, 101) The Pages of the Analytics Component were my guide on how to vary the data - when the UX Designer worked on this, what data did they or the business expect? If there was a ranking I decided in the implementation which subset of models would be used more often to from relations to have live-like rankings. Keep it simple: Whenever there was a model that was not in any way needed to display the Analytics Component - I would not seed it. Using the Demo Env as Stress Test and Bug Revealer #Some writing of colorful text on dark background later we deployed and watched the system taking disturbing 16 seconds to load some pages. Did I mention that the company was a Start-Up without a customer who had been causing data of that size for a year? The product owner opened a fresh pack of post-its to note down every end-point that required query optimisation as we developers got shameful credit for the not scalable system we had built. Additionally, not all graphs that we did imagine worked out with that many data points, while some other inspired completely new ways do structure the data.\nDevelopment Process Learning: Having a demo environment with generated data can point out response time problems, visualisation problems and be an inspiring point of view for UX and Code Development The query optimisation was not too hard, avoid over-fetching, let SQL do whatever it can to faster than PHP, and use eager loading whenever possible. The big learning of this experience was not how I optimised the queries, but how the bottleneck was discovered. The reason I write this article is, that I recommend any high aiming Start Up to try this. Not only is it a nice feature to present your investors a view on your page \u0026ldquo;if people would use it\u0026rdquo;, but also it can uncover some bottlenecks you mind not have thought of in an early stage but would regret in case of that exponential growth the business owner is promising next month.\n","date":"11 May 2022","permalink":"/posts/2022-05-demo-env/","section":"Posts","summary":"I got the task to implement a Demo environment, learned something about Laravel Factories and the usage of an environment to give possible customers / investors a taste of your product and the developers to find response time / query problems and UX bugs A \u0026ldquo;Demo\u0026rdquo; Feature Request #This card was proposed in a sprint planning and sparked a discussion around multiple problems and ideas.","title":"Demo Environments and what I learned from implementing one"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"}]